{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjaliAleti/Aleti_INFO5731_Fall2024/blob/main/Aleti__Anjali_Assignment_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 1**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (25 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2024 or 2025 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "\n",
        "(3) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(4) Collect all the information of the 904 narrators in the Densho Digital Repository.\n",
        "\n",
        "(5)**Collect a total of 10000 reviews** of the top 100 most popular software from G2 and Capterra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDyTKYs-yGit"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "!pip -q install pandas tqdm requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip -q install pandas tqdm requests\n",
        "\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "API_KEY = \"\"\n",
        "\n",
        "QUERY = \"machine learning\"\n",
        "TARGET_N = 10000\n",
        "SLEEP_SECONDS = 1.1\n",
        "OUT_CSV = f\"semantic_scholar_{QUERY.replace(' ','_')}_{TARGET_N}.csv\"\n",
        "\n",
        "BASE_URL = \"https://api.semanticscholar.org/graph/v1/paper/search/bulk\"\n",
        "FIELDS = \"paperId,title,abstract,year,venue,url,authors\"\n",
        "\n",
        "\n",
        "headers = {}\n",
        "if isinstance(API_KEY, str) and API_KEY.strip():\n",
        "    headers[\"x-api-key\"] = API_KEY.strip()\n",
        "\n",
        "def fetch_with_retries(url, params, headers, max_retries=8):\n",
        "    \"\"\"Robust GET with retries/backoff for rate limits (429) and server errors.\"\"\"\n",
        "    backoff = 1.0\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            r = requests.get(url, params=params, headers=headers, timeout=60)\n",
        "\n",
        "            if r.status_code == 200:\n",
        "                return r.json()\n",
        "\n",
        "            elif r.status_code == 429:\n",
        "\n",
        "                print(f\"429 Rate limit hit. Sleeping {backoff:.1f}s...\")\n",
        "                time.sleep(backoff)\n",
        "                backoff = min(backoff * 2, 60)\n",
        "\n",
        "            elif 500 <= r.status_code < 600:\n",
        "\n",
        "                print(f\"{r.status_code} Server error. Sleeping {backoff:.1f}s...\")\n",
        "                time.sleep(backoff)\n",
        "                backoff = min(backoff * 2, 60)\n",
        "\n",
        "            else:\n",
        "\n",
        "                raise RuntimeError(f\"HTTP {r.status_code}: {r.text[:300]}\")\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            print(\"Request exception:\", e, f\"| Sleeping {backoff:.1f}s...\")\n",
        "            time.sleep(backoff)\n",
        "            backoff = min(backoff * 2, 60)\n",
        "\n",
        "    raise RuntimeError(\"Max retries exceeded (API not responding or rate limited too long).\")\n",
        "\n",
        "\n",
        "all_rows = []\n",
        "seen_ids = set()\n",
        "\n",
        "params = {\n",
        "    \"query\": QUERY,\n",
        "    \"fields\": FIELDS\n",
        "}\n",
        "\n",
        "print(f\"Starting bulk search for query: {QUERY}\")\n",
        "resp = fetch_with_retries(BASE_URL, params=params, headers=headers)\n",
        "\n",
        "estimated_total = resp.get(\"total\", None)\n",
        "if estimated_total is not None:\n",
        "    print(f\"Estimated matches: {estimated_total}\")\n",
        "\n",
        "pbar = tqdm(total=TARGET_N, desc=\"Collected abstracts\", unit=\"paper\")\n",
        "\n",
        "while True:\n",
        "    data = resp.get(\"data\", [])\n",
        "    if not data:\n",
        "        print(\"No more data returned. Stopping.\")\n",
        "        break\n",
        "\n",
        "    for paper in data:\n",
        "        if len(all_rows) >= TARGET_N:\n",
        "            break\n",
        "\n",
        "        pid = paper.get(\"paperId\")\n",
        "        if not pid or pid in seen_ids:\n",
        "            continue\n",
        "\n",
        "        seen_ids.add(pid)\n",
        "\n",
        "        authors = paper.get(\"authors\", [])\n",
        "        author_names = \", \".join([a.get(\"name\", \"\").strip() for a in authors if a.get(\"name\")])\n",
        "\n",
        "        row = {\n",
        "            \"paperId\": pid,\n",
        "            \"title\": paper.get(\"title\", \"\"),\n",
        "            \"abstract\": paper.get(\"abstract\", \"\"),\n",
        "            \"year\": paper.get(\"year\", \"\"),\n",
        "            \"venue\": paper.get(\"venue\", \"\"),\n",
        "            \"url\": paper.get(\"url\", \"\"),\n",
        "            \"authors\": author_names\n",
        "        }\n",
        "\n",
        "        all_rows.append(row)\n",
        "        pbar.update(1)\n",
        "\n",
        "    if len(all_rows) >= TARGET_N:\n",
        "        print(\"Reached TARGET_N. Stopping.\")\n",
        "        break\n",
        "\n",
        "    token = resp.get(\"token\")\n",
        "    if not token:\n",
        "        print(\"No token for next page. Stopping.\")\n",
        "        break\n",
        "\n",
        "    params = {\n",
        "        \"query\": QUERY,\n",
        "        \"fields\": FIELDS,\n",
        "        \"token\": token\n",
        "    }\n",
        "\n",
        "    time.sleep(SLEEP_SECONDS)\n",
        "    resp = fetch_with_retries(BASE_URL, params=params, headers=headers)\n",
        "\n",
        "pbar.close()\n",
        "\n",
        "\n",
        "df = pd.DataFrame(all_rows)\n",
        "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"\\n✅ Saved {len(df)} records to: {OUT_CSV}\")\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729,
          "referenced_widgets": [
            "d224577e52a440568201117cd597c989",
            "c6263449a4344aedb0713ca326da1ed9",
            "ce354b51b28044c598e39f32790974db",
            "52241b96dadf4d9e9d6cfc40e4592a7a",
            "291b0b40f2774d6abeeba5d11b855280",
            "4dbbff4950904ed49c0ad495180776b9",
            "715e25b27f6a4281bd58272c64670898",
            "4ff8c9b583754063b6ffb305fc2b27fb",
            "ba55058cccec4d33a18e2c222566a455",
            "125fcee5a2e245fcadb5a7f5e82ec52f",
            "7f8c29cb10dc4376b90fd3fb40cce845"
          ]
        },
        "id": "lNlY3o1HZDUH",
        "outputId": "199fc496-6fd9-42a1-d6f7-746deccec5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting bulk search for query: machine learning\n",
            "Estimated matches: 1017240\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Collected abstracts:   0%|          | 0/10000 [00:00<?, ?paper/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d224577e52a440568201117cd597c989"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No token for next page. Stopping.\n",
            "\n",
            "✅ Saved 2936 records to: semantic_scholar_machine_learning_10000.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    paperId  \\\n",
              "0  00000c33779acab142af6c7a6dae8b36fac0805d   \n",
              "1  0000238f07f151172cf2602588ba762b55c8464b   \n",
              "2  00002d31a8c758062a51d9a259313d81a5eaf399   \n",
              "3  0000315635be19f6278dbc72597b3065fac405f0   \n",
              "4  00005d68c6c7eb4d3c27da8242a30b9a498f991e   \n",
              "\n",
              "                                               title  \\\n",
              "0  Insights into Household Electric Vehicle Charg...   \n",
              "1  Personalized Prediction of Response to Smartph...   \n",
              "2  A Machine Learning Method to Quantify the Role...   \n",
              "3  Abstractive text summarization of low-resource...   \n",
              "4  Detection of DDoS Attacks on Clouds Computing ...   \n",
              "\n",
              "                                            abstract    year  \\\n",
              "0  In the era of burgeoning electric vehicle (EV)...  2024.0   \n",
              "1  Background Meditation apps have surged in popu...  2021.0   \n",
              "2                                               None  2020.0   \n",
              "3  Background Humans must be able to cope with th...  2023.0   \n",
              "4  The growing number of cloud-based services has...  2023.0   \n",
              "\n",
              "                                               venue  \\\n",
              "0                                           Energies   \n",
              "1               Journal of Medical Internet Research   \n",
              "2  International Conference on Information System...   \n",
              "3                             PeerJ Computer Science   \n",
              "4  International Conference on Communication and ...   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://www.semanticscholar.org/paper/00000c33...   \n",
              "1  https://www.semanticscholar.org/paper/0000238f...   \n",
              "2  https://www.semanticscholar.org/paper/00002d31...   \n",
              "3  https://www.semanticscholar.org/paper/00003156...   \n",
              "4  https://www.semanticscholar.org/paper/00005d68...   \n",
              "\n",
              "                                             authors  \n",
              "0  Ahmad Almaghrebi, Kevin James, Fares al Juhesh...  \n",
              "1  Christian A. Webb, M. Hirshberg, R. Davidson, ...  \n",
              "2     L. Szczyrba, Yang Zhang, D. Pamukçu, D. Eroglu  \n",
              "3  Nida Shafiq, Isma Hamid, Muhammad Asif, Qamar ...  \n",
              "4                     Iehab Alrassan, Asma Alqahtani  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c99d537-adf8-44cc-b1e2-65cf7d87a7b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paperId</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>year</th>\n",
              "      <th>venue</th>\n",
              "      <th>url</th>\n",
              "      <th>authors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000c33779acab142af6c7a6dae8b36fac0805d</td>\n",
              "      <td>Insights into Household Electric Vehicle Charg...</td>\n",
              "      <td>In the era of burgeoning electric vehicle (EV)...</td>\n",
              "      <td>2024.0</td>\n",
              "      <td>Energies</td>\n",
              "      <td>https://www.semanticscholar.org/paper/00000c33...</td>\n",
              "      <td>Ahmad Almaghrebi, Kevin James, Fares al Juhesh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000238f07f151172cf2602588ba762b55c8464b</td>\n",
              "      <td>Personalized Prediction of Response to Smartph...</td>\n",
              "      <td>Background Meditation apps have surged in popu...</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>Journal of Medical Internet Research</td>\n",
              "      <td>https://www.semanticscholar.org/paper/0000238f...</td>\n",
              "      <td>Christian A. Webb, M. Hirshberg, R. Davidson, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00002d31a8c758062a51d9a259313d81a5eaf399</td>\n",
              "      <td>A Machine Learning Method to Quantify the Role...</td>\n",
              "      <td>None</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>International Conference on Information System...</td>\n",
              "      <td>https://www.semanticscholar.org/paper/00002d31...</td>\n",
              "      <td>L. Szczyrba, Yang Zhang, D. Pamukçu, D. Eroglu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000315635be19f6278dbc72597b3065fac405f0</td>\n",
              "      <td>Abstractive text summarization of low-resource...</td>\n",
              "      <td>Background Humans must be able to cope with th...</td>\n",
              "      <td>2023.0</td>\n",
              "      <td>PeerJ Computer Science</td>\n",
              "      <td>https://www.semanticscholar.org/paper/00003156...</td>\n",
              "      <td>Nida Shafiq, Isma Hamid, Muhammad Asif, Qamar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00005d68c6c7eb4d3c27da8242a30b9a498f991e</td>\n",
              "      <td>Detection of DDoS Attacks on Clouds Computing ...</td>\n",
              "      <td>The growing number of cloud-based services has...</td>\n",
              "      <td>2023.0</td>\n",
              "      <td>International Conference on Communication and ...</td>\n",
              "      <td>https://www.semanticscholar.org/paper/00005d68...</td>\n",
              "      <td>Iehab Alrassan, Asma Alqahtani</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c99d537-adf8-44cc-b1e2-65cf7d87a7b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c99d537-adf8-44cc-b1e2-65cf7d87a7b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c99d537-adf8-44cc-b1e2-65cf7d87a7b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2936,\n  \"fields\": [\n    {\n      \"column\": \"paperId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2936,\n        \"samples\": [\n          \"005bb7b6c6dbbbb3f2da59ba9c82da3fd3cf522f\",\n          \"005bef13c1990bd6bd88eafa0fbe7fdbbefb75f4\",\n          \"004ee996e1575415f924ede997613371508c7517\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2936,\n        \"samples\": [\n          \"Improvement in Land Cover and Crop Classification based on Temporal Features Learning from Sentinel-2 Data Using Recurrent-Convolutional Neural Network (R-CNN)\",\n          \"Predicting Votes from Census Data\",\n          \"Estimating Value of Customer through Store Check-in Histories and its Application for Visitor Promotion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1921,\n        \"samples\": [\n          \"The most significant and rapidly expanding fintech services in Nepal are provided by several fintech firms. Customer satisfaction must be compared side by side even if every organization has made an effort to expand the usage of services. Many studies have concentrated on evaluating the impact of various factors on customer satisfaction, but significantly fewer studies have been conducted to explore the factors and focus of machine learning. Based on the planned behavioural theory (TPB), the study is concentrated on exploring and evaluating customer satisfaction on a different stimulus offered by F1 Soft (a fintech firm in nepal), customers\\u2019 loyalty and the compatibility they gain through the company\\u2019s services. By exploring various factors affecting customer satisfaction by using principal component analysis (PCA) and explainable AI (XAI), the study explored the eight factors (customer service, compatibility, ease of use, assurance, loyalty intention, technology perception, speed and firm\\u2019s innovativeness) which affect customer satisfaction individually. Furthermore, by using support vector machine (SVM) and logistic regression (LR), the major contributing factors are explained with local interpretable model-agnostic explanation (LIME) and Shapley additive explanations (SHAP). SVM holds the training accuracy of 89.13% whereas LR achieves 87.88%, and both algorithms show that compatibilty issues consider the major contributing factor for customer satisfaction. Contributing toward different dimensions, determinants, and the results of customer satisfaction in fintech, the study suggests how fintech companies must integrate factors affecting customer satisfaction in their system for further process development.\",\n          \"To determine whether a document or a sentence expresses a positive or negative sentiment, three main approach types are commonly used: lexicon based approaches, machine learning (ML) based approaches and hybrid approaches. English has the greatest number of sentiment analysis studies, unlike other languages including Arabic and its dialects. More specifically, ML based sentiment analysis requires annotated data. In the case of lexicon based approaches, they typically require the availability of lexicons annotated by valence and/or intensity. One of the majors problems related to the treatment of Arabic and its dialect is the lack of the above resources. This survey is aimed to highlight the most recent resources that have been constructed and most recent advances in the context of sentiment analysis (related to English and Arabic language). It refers to about one hundred recent papers, most of which published between 2015 and 2018. These works are classified by category (as survey work vs. solution work). In the case of solution works, we focus on the construction of sentiment lexicon and corpus. We also propose new trends in Arabic sentiment analysis, mainly employing deep learning techniques.\",\n          \"This study aims to identify the root causes of customer churn in the telecommunications industry and to predict churn using network-related indicators. Unlike many previous studies that rely on billing or campaign-related variables, this work focuses solely on network performance metrics (KPIs) that reflect real customer experience \\u2014 including streaming quality, end-to-end delay, VoLTE QoE, and overall network quality indicators. As the dataset does not contain any economic or tariff-related information, the results specifically reflect the impact of non-economical churn drivers. A 30-day average of daily KPIs was calculated for each customer across 2G, 3G, and 4G technologies, and a representative sample was selected for clustering. Bisecting K-Means algorithms were applied to segment customers. The segment identified with poor network performance showed significantly higher churn compared to other groups, revealing a strong link between degraded network experience and churn behavior. Subsequently, ANOVA was used to identify the most influential features on churn, and several machine learning models were trained using only the statistically significant variables. The models' precision and recall scores were compared to determine the best-performing model. As the initial results were not satisfactory, a more focused case study was conducted using 30-Day Daily Time Series per Customer data for the Kad\\u0131koy, Sisli, Uskudar, Besiktas districts of Istanbul. Churn prediction was then performed on a balanced dataset, created by sampling an equal number of non-churners to match the churners in the same period, achieving an F1-score of 62 %.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.486450734389502,\n        \"min\": 1897.0,\n        \"max\": 2026.0,\n        \"num_unique_values\": 45,\n        \"samples\": [\n          1987.0,\n          1995.0,\n          2009.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1774,\n        \"samples\": [\n          \"AIMS Mathematics\",\n          \"Found. Trends Mach. Learn.\",\n          \"Transportation Research Record\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2936,\n        \"samples\": [\n          \"https://www.semanticscholar.org/paper/005bb7b6c6dbbbb3f2da59ba9c82da3fd3cf522f\",\n          \"https://www.semanticscholar.org/paper/005bef13c1990bd6bd88eafa0fbe7fdbbefb75f4\",\n          \"https://www.semanticscholar.org/paper/004ee996e1575415f924ede997613371508c7517\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2897,\n        \"samples\": [\n          \"Ngoc-Huynh Ho, S. Charisis, Nicolas Honnorat, Sachintha R. Brandigampala, Di Wang, S. Heckbert, Peter T. Fox, David M Martinez, David H. Wang, Timothy M Hughes, D. Archer, Timothy J. Hohman, Sudha Seshadri, C. Davatzikos, Mohamad Habes\",\n          \"M. Pardo, Guillermo Strack, Diego C. Mart\\u00ednez\",\n          \"Naresh B. Ravichandran, A. Lansner, P. Herman\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(OUT_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TXQ4fO1fcXdM",
        "outputId": "a7d8f563-6e59-444b-82e9-28947aa616b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e2954ff7-9968-44ba-a8bb-fb22e5fff2d6\", \"github_marketplace_actions_1000.csv\", 84436)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (15 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QX6bJjGWXY9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a99287ad-87f3-4355-d180-576c912cfb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 10000\n",
            "Columns: ['paperId', 'title', 'abstract', 'year', 'venue', 'url', 'authors']\n",
            "\n",
            "Sample raw text (first 3):\n",
            "\n",
            "--- Sample 1 ---\n",
            "In the era of burgeoning electric vehicle (EV) popularity, understanding the patterns of EV users’ behavior is imperative. This paper examines the trends in household charging sessions’ timing, duration, and energy consumption by analyzing real-world residential charging data. By leveraging the information collected from each session, a novel framework is introduced for the efficient, real-time prediction of important charging characteristics. Utilizing historical data and user-specific features, machine learning models are trained to predict the connection duration, charging duration, chargin\n",
            "\n",
            "--- Sample 2 ---\n",
            "Background Meditation apps have surged in popularity in recent years, with an increasing number of individuals turning to these apps to cope with stress, including during the COVID-19 pandemic. Meditation apps are the most commonly used mental health apps for depression and anxiety. However, little is known about who is well suited to these apps. Objective This study aimed to develop and test a data-driven algorithm to predict which individuals are most likely to benefit from app-based meditation training. Methods Using randomized controlled trial data comparing a 4-week meditation app (Health\n",
            "\n",
            "--- Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 1 OUTPUT (Noise removed)\n",
            "==============================\n",
            "\n",
            "--- Step1 Sample 1 ---\n",
            "In the era of burgeoning electric vehicle EV popularity understanding the patterns of EV users behavior is imperative This paper examines the trends in household charging sessions timing duration and energy consumption by analyzing real world residential charging data By leveraging the information collected from each session a novel framework is introduced for the efficient real time prediction of important charging characteristics Utilizing historical data and user specific features machine learning models are trained to predict the connection duration charging duration charging demand and ti\n",
            "\n",
            "--- Step1 Sample 2 ---\n",
            "Background Meditation apps have surged in popularity in recent years with an increasing number of individuals turning to these apps to cope with stress including during the COVID 19 pandemic Meditation apps are the most commonly used mental health apps for depression and anxiety However little is known about who is well suited to these apps Objective This study aimed to develop and test a data driven algorithm to predict which individuals are most likely to benefit from app based meditation training Methods Using randomized controlled trial data comparing a 4 week meditation app Healthy Minds \n",
            "\n",
            "--- Step1 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 2 OUTPUT (Numbers removed)\n",
            "==============================\n",
            "\n",
            "--- Step2 Sample 1 ---\n",
            "In the era of burgeoning electric vehicle EV popularity understanding the patterns of EV users behavior is imperative This paper examines the trends in household charging sessions timing duration and energy consumption by analyzing real world residential charging data By leveraging the information collected from each session a novel framework is introduced for the efficient real time prediction of important charging characteristics Utilizing historical data and user specific features machine learning models are trained to predict the connection duration charging duration charging demand and ti\n",
            "\n",
            "--- Step2 Sample 2 ---\n",
            "Background Meditation apps have surged in popularity in recent years with an increasing number of individuals turning to these apps to cope with stress including during the COVID pandemic Meditation apps are the most commonly used mental health apps for depression and anxiety However little is known about who is well suited to these apps Objective This study aimed to develop and test a data driven algorithm to predict which individuals are most likely to benefit from app based meditation training Methods Using randomized controlled trial data comparing a week meditation app Healthy Minds Progr\n",
            "\n",
            "--- Step2 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 3 OUTPUT (Stopwords removed)\n",
            "==============================\n",
            "\n",
            "--- Step3 Sample 1 ---\n",
            "era burgeoning electric vehicle EV popularity understanding patterns EV users behavior imperative paper examines trends household charging sessions timing duration energy consumption analyzing real world residential charging data leveraging information collected session novel framework introduced efficient real time prediction important charging characteristics Utilizing historical data user specific features machine learning models trained predict connection duration charging duration charging demand time next session models enhance understanding EV users behavior provide practical tools opti\n",
            "\n",
            "--- Step3 Sample 2 ---\n",
            "Background Meditation apps surged popularity recent years increasing number individuals turning apps cope stress including COVID pandemic Meditation apps commonly used mental health apps depression anxiety However little known well suited apps Objective study aimed develop test data driven algorithm predict individuals likely benefit app based meditation training Methods Using randomized controlled trial data comparing week meditation app Healthy Minds Program HMP assessment control condition school system employees n developed algorithm predict likely benefit HMP Baseline clinical demographic\n",
            "\n",
            "--- Step3 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 4 OUTPUT (Lowercased)\n",
            "==============================\n",
            "\n",
            "--- Step4 Sample 1 ---\n",
            "era burgeoning electric vehicle ev popularity understanding patterns ev users behavior imperative paper examines trends household charging sessions timing duration energy consumption analyzing real world residential charging data leveraging information collected session novel framework introduced efficient real time prediction important charging characteristics utilizing historical data user specific features machine learning models trained predict connection duration charging duration charging demand time next session models enhance understanding ev users behavior provide practical tools opti\n",
            "\n",
            "--- Step4 Sample 2 ---\n",
            "background meditation apps surged popularity recent years increasing number individuals turning apps cope stress including covid pandemic meditation apps commonly used mental health apps depression anxiety however little known well suited apps objective study aimed develop test data driven algorithm predict individuals likely benefit app based meditation training methods using randomized controlled trial data comparing week meditation app healthy minds program hmp assessment control condition school system employees n developed algorithm predict likely benefit hmp baseline clinical demographic\n",
            "\n",
            "--- Step4 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 5 OUTPUT (Stemmed)\n",
            "==============================\n",
            "\n",
            "--- Step5 Sample 1 ---\n",
            "era burgeon electr vehicl ev popular understand pattern ev user behavior imper paper examin trend household charg session time durat energi consumpt analyz real world residenti charg data leverag inform collect session novel framework introduc effici real time predict import charg characterist util histor data user specif featur machin learn model train predict connect durat charg durat charg demand time next session model enhanc understand ev user behavior provid practic tool optim ev charg infrastructur effect manag charg demand transport sector becom increasingli electrifi work aim empow st\n",
            "\n",
            "--- Step5 Sample 2 ---\n",
            "background medit app surg popular recent year increas number individu turn app cope stress includ covid pandem medit app commonli use mental health app depress anxieti howev littl known well suit app object studi aim develop test data driven algorithm predict individu like benefit app base medit train method use random control trial data compar week medit app healthi mind program hmp assess control condit school system employe n develop algorithm predict like benefit hmp baselin clinic demograph characterist submit machin learn model develop person advantag index pai reflect individu expect re\n",
            "\n",
            "--- Step5 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 6 OUTPUT (Lemmatized)\n",
            "==============================\n",
            "\n",
            "--- Step6 Sample 1 ---\n",
            "era burgeoning electric vehicle ev popularity understanding pattern ev user behavior imperative paper examines trend household charging session timing duration energy consumption analyzing real world residential charging data leveraging information collected session novel framework introduced efficient real time prediction important charging characteristic utilizing historical data user specific feature machine learning model trained predict connection duration charging duration charging demand time next session model enhance understanding ev user behavior provide practical tool optimizing ev \n",
            "\n",
            "--- Step6 Sample 2 ---\n",
            "background meditation apps surged popularity recent year increasing number individual turning apps cope stress including covid pandemic meditation apps commonly used mental health apps depression anxiety however little known well suited apps objective study aimed develop test data driven algorithm predict individual likely benefit app based meditation training method using randomized controlled trial data comparing week meditation app healthy mind program hmp assessment control condition school system employee n developed algorithm predict likely benefit hmp baseline clinical demographic chara\n",
            "\n",
            "--- Step6 Sample 3 ---\n",
            "\n",
            "\n",
            "✅ Saved cleaned CSV with new column 'clean_text' to: semantic_scholar_machine_learning_10000_cleaned.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            abstract  \\\n",
              "0  In the era of burgeoning electric vehicle (EV)...   \n",
              "1  Background Meditation apps have surged in popu...   \n",
              "2                                                NaN   \n",
              "3  Background Humans must be able to cope with th...   \n",
              "4  The growing number of cloud-based services has...   \n",
              "\n",
              "                                          clean_text  \n",
              "0  era burgeoning electric vehicle ev popularity ...  \n",
              "1  background meditation apps surged popularity r...  \n",
              "2                                                     \n",
              "3  background human must able cope huge amount in...  \n",
              "4  growing number cloud based service led rising ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04def6c7-a31a-4b71-b369-2c5af6016539\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the era of burgeoning electric vehicle (EV)...</td>\n",
              "      <td>era burgeoning electric vehicle ev popularity ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Background Meditation apps have surged in popu...</td>\n",
              "      <td>background meditation apps surged popularity r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Background Humans must be able to cope with th...</td>\n",
              "      <td>background human must able cope huge amount in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The growing number of cloud-based services has...</td>\n",
              "      <td>growing number cloud based service led rising ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04def6c7-a31a-4b71-b369-2c5af6016539')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04def6c7-a31a-4b71-b369-2c5af6016539 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04def6c7-a31a-4b71-b369-2c5af6016539');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[[TEXT_COL, \\\"clean_text\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Background Meditation apps have surged in popularity in recent years, with an increasing number of individuals turning to these apps to cope with stress, including during the COVID-19 pandemic. Meditation apps are the most commonly used mental health apps for depression and anxiety. However, little is known about who is well suited to these apps. Objective This study aimed to develop and test a data-driven algorithm to predict which individuals are most likely to benefit from app-based meditation training. Methods Using randomized controlled trial data comparing a 4-week meditation app (Healthy Minds Program [HMP]) with an assessment-only control condition in school system employees (n=662), we developed an algorithm to predict who is most likely to benefit from HMP. Baseline clinical and demographic characteristics were submitted to a machine learning model to develop a \\u201cPersonalized Advantage Index\\u201d (PAI) reflecting an individual\\u2019s expected reduction in distress (primary outcome) from HMP versus control. Results A significant group \\u00d7 PAI interaction emerged (t658=3.30; P=.001), indicating that PAI scores moderated group differences in outcomes. A regression model that included repetitive negative thinking as the sole baseline predictor performed comparably well. Finally, we demonstrate the translation of a predictive model into personalized recommendations of expected benefit. Conclusions Overall, the results revealed the potential of a data-driven algorithm to inform which individuals are most likely to benefit from a meditation app. Such an algorithm could be used to objectively communicate expected benefits to individuals, allowing them to make more informed decisions about whether a meditation app is appropriate for them. Trial Registration ClinicalTrials.gov NCT04426318; https://clinicaltrials.gov/ct2/show/NCT04426318\",\n          \"The growing number of cloud-based services has led to a rising threat of Distributed Denial of Service (DDoS) attacks. These attacks can cause significant harm to businesses and organizations by overwhelming their network resources, resulting in the unavailability of critical services. The traditional defense mechanisms, such as firewalls systems, are becoming insufficient to cope with the scale and complexity of DDoS attacks. In this research, we propose a new machine learning approach based on ensemble learning to detect DDoS attacks in cloud environments. The proposed method utilizes various features extracted from network traffic to train machine learning algorithms. The proposed solution is expected to be effective in detecting DDoS attacks in real-time with high accuracy.\",\n          \"In the era of burgeoning electric vehicle (EV) popularity, understanding the patterns of EV users\\u2019 behavior is imperative. This paper examines the trends in household charging sessions\\u2019 timing, duration, and energy consumption by analyzing real-world residential charging data. By leveraging the information collected from each session, a novel framework is introduced for the efficient, real-time prediction of important charging characteristics. Utilizing historical data and user-specific features, machine learning models are trained to predict the connection duration, charging duration, charging demand, and time until the next session. These models enhance the understanding of EV users\\u2019 behavior and provide practical tools for optimizing the EV charging infrastructure and effectively managing the charging demand. As the transportation sector becomes increasingly electrified, this work aims to empower stakeholders with insights and reliable models, enabling them to anticipate the localized demand and contribute to the sustainable integration of electric vehicles into the grid.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"background meditation apps surged popularity recent year increasing number individual turning apps cope stress including covid pandemic meditation apps commonly used mental health apps depression anxiety however little known well suited apps objective study aimed develop test data driven algorithm predict individual likely benefit app based meditation training method using randomized controlled trial data comparing week meditation app healthy mind program hmp assessment control condition school system employee n developed algorithm predict likely benefit hmp baseline clinical demographic characteristic submitted machine learning model develop personalized advantage index pai reflecting individual expected reduction distress primary outcome hmp versus control result significant group pai interaction emerged p indicating pai score moderated group difference outcome regression model included repetitive negative thinking sole baseline predictor performed comparably well finally demonstrate translation predictive model personalized recommendation expected benefit conclusion overall result revealed potential data driven algorithm inform individual likely benefit meditation app algorithm could used objectively communicate expected benefit individual allowing make informed decision whether meditation app appropriate trial registration clinicaltrials gov nct http clinicaltrials gov ct show nct\",\n          \"growing number cloud based service led rising threat distributed denial service ddos attack attack cause significant harm business organization overwhelming network resource resulting unavailability critical service traditional defense mechanism firewall system becoming insufficient cope scale complexity ddos attack research propose new machine learning approach based ensemble learning detect ddos attack cloud environment proposed method utilizes various feature extracted network traffic train machine learning algorithm proposed solution expected effective detecting ddos attack real time high accuracy\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "!pip -q install pandas nltk\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "\n",
        "INPUT_CSV = \"semantic_scholar_machine_learning_10000.csv\"\n",
        "TEXT_COL = \"abstract\"\n",
        "\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "sample_series = df[TEXT_COL].fillna(\"\").astype(str).head(3)\n",
        "print(\"\\nSample raw text (first 3):\")\n",
        "for i, t in enumerate(sample_series, start=1):\n",
        "    print(f\"\\n--- Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "def remove_noise(text: str) -> str:\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "step1 = sample_series.apply(remove_noise)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 1 OUTPUT (Noise removed)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step1, start=1):\n",
        "    print(f\"\\n--- Step1 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "def remove_numbers(text: str) -> str:\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "step2 = step1.apply(remove_numbers)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 2 OUTPUT (Numbers removed)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step2, start=1):\n",
        "    print(f\"\\n--- Step2 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered = [w for w in tokens if w.lower() not in STOPWORDS]\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "step3 = step2.apply(remove_stopwords)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 3 OUTPUT (Stopwords removed)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step3, start=1):\n",
        "    print(f\"\\n--- Step3 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "def to_lower(text: str) -> str:\n",
        "    return text.lower()\n",
        "\n",
        "step4 = step3.apply(to_lower)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 4 OUTPUT (Lowercased)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step4, start=1):\n",
        "    print(f\"\\n--- Step4 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_text(text: str) -> str:\n",
        "    tokens = word_tokenize(text)\n",
        "    stemmed = [stemmer.stem(w) for w in tokens]\n",
        "    return \" \".join(stemmed)\n",
        "\n",
        "step5 = step4.apply(stem_text)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 5 OUTPUT (Stemmed)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step5, start=1):\n",
        "    print(f\"\\n--- Step5 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text: str) -> str:\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmas = [lemmatizer.lemmatize(w) for w in tokens]\n",
        "    return \" \".join(lemmas)\n",
        "\n",
        "step6 = step4.apply(lemmatize_text)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 6 OUTPUT (Lemmatized)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step6, start=1):\n",
        "    print(f\"\\n--- Step6 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "def full_clean_pipeline(text: str) -> str:\n",
        "    if pd.isna(text):\n",
        "        text = \"\"\n",
        "    text = str(text)\n",
        "\n",
        "    text = remove_noise(text)\n",
        "    text = remove_numbers(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = to_lower(text)\n",
        "    text = lemmatize_text(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "df[\"clean_text\"] = df[TEXT_COL].apply(full_clean_pipeline)\n",
        "\n",
        "OUTPUT_CSV = INPUT_CSV.replace(\".csv\", \"_cleaned.csv\")\n",
        "df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n✅ Saved cleaned CSV with new column 'clean_text' to:\", OUTPUT_CSV)\n",
        "\n",
        "\n",
        "df[[TEXT_COL, \"clean_text\"]].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(OUTPUT_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RytSbTtHeDoh",
        "outputId": "2d1f3ec2-6ae6-4fb7-a228-55e8d8479ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_663ccf5a-a0d6-4ed3-8099-20b84620a633\", \"semantic_scholar_machine_learning_10000_cleaned.csv\", 19837620)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (15 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0oOSlsOS0cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39492241-1da1-4633-c80b-5ab5a04ec9e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Rows: 10000\n",
            "Columns: ['paperId', 'title', 'abstract', 'year', 'venue', 'url', 'authors', 'clean_text']\n",
            "\n",
            "==============================\n",
            "EXAMPLE SENTENCE (used for parsing)\n",
            "==============================\n",
            "era burgeoning electric vehicle ev popularity understanding pattern ev user behavior imperative paper examines trend household charging session timing duration energy consumption analyzing real world residential charging data leveraging information collected session novel framework introduced efficient real time prediction important charging characteristic utilizing historical data user specific feature machine learning model trained predict connection duration charging duration charging demand time next session model enhance understanding ev user behavior provide practical tool optimizing ev charging infrastructure effectively managing charging demand transportation sector becomes increasingly electrified work aim empower stakeholder insight reliable model enabling anticipate localized demand contribute sustainable integration electric vehicle grid\n",
            "\n",
            "==============================\n",
            "PART (1) POS TAGGING COUNTS\n",
            "==============================\n",
            "Processed rows: 1000\n",
            "Total Nouns: 50005\n",
            "Total Verbs: 16380\n",
            "Total Adjectives: 21171\n",
            "Total Adverbs: 3739\n",
            "\n",
            "POS tags for example sentence:\n",
            "[('era', 'NN'), ('burgeoning', 'VBG'), ('electric', 'JJ'), ('vehicle', 'NN'), ('ev', 'NN'), ('popularity', 'NN'), ('understanding', 'VBG'), ('pattern', 'JJ'), ('ev', 'JJ'), ('user', 'NN'), ('behavior', 'NN'), ('imperative', 'JJ'), ('paper', 'NN'), ('examines', 'NNS'), ('trend', 'NN'), ('household', 'NN'), ('charging', 'VBG'), ('session', 'NN'), ('timing', 'VBG'), ('duration', 'NN'), ('energy', 'NN'), ('consumption', 'NN'), ('analyzing', 'VBG'), ('real', 'JJ'), ('world', 'NN'), ('residential', 'JJ'), ('charging', 'VBG'), ('data', 'NNS'), ('leveraging', 'VBG'), ('information', 'NN'), ('collected', 'VBN'), ('session', 'NN'), ('novel', 'NN'), ('framework', 'NN'), ('introduced', 'VBD'), ('efficient', 'JJ'), ('real', 'JJ'), ('time', 'NN'), ('prediction', 'NN'), ('important', 'JJ'), ('charging', 'VBG'), ('characteristic', 'JJ'), ('utilizing', 'JJ'), ('historical', 'JJ'), ('data', 'NNS'), ('user', 'NN'), ('specific', 'JJ'), ('feature', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('trained', 'VBD'), ('predict', 'JJ'), ('connection', 'NN'), ('duration', 'NN'), ('charging', 'VBG'), ('duration', 'NN'), ('charging', 'VBG'), ('demand', 'NN'), ('time', 'NN'), ('next', 'JJ'), ('session', 'NN'), ('model', 'NN'), ('enhance', 'NN'), ('understanding', 'VBG'), ('ev', 'CC'), ('user', 'JJ'), ('behavior', 'NN'), ('provide', 'VBP'), ('practical', 'JJ'), ('tool', 'NN'), ('optimizing', 'VBG'), ('ev', 'JJ'), ('charging', 'VBG'), ('infrastructure', 'NN'), ('effectively', 'RB'), ('managing', 'VBG'), ('charging', 'VBG'), ('demand', 'NN'), ('transportation', 'NN'), ('sector', 'NN'), ('becomes', 'VBZ'), ('increasingly', 'RB'), ('electrified', 'JJ'), ('work', 'NN'), ('aim', 'NN'), ('empower', 'VB'), ('stakeholder', 'NN'), ('insight', 'NN'), ('reliable', 'JJ'), ('model', 'NN'), ('enabling', 'VBG'), ('anticipate', 'JJ'), ('localized', 'VBN'), ('demand', 'NN'), ('contribute', 'NN'), ('sustainable', 'JJ'), ('integration', 'NN'), ('electric', 'JJ'), ('vehicle', 'NN'), ('grid', 'NN')]\n",
            "\n",
            "==============================\n",
            "PART (2) CONSTITUENCY TREE (NLTK ne_chunk Tree)\n",
            "==============================\n",
            "(S\n",
            "  era/NN\n",
            "  burgeoning/VBG\n",
            "  electric/JJ\n",
            "  vehicle/NN\n",
            "  ev/NN\n",
            "  popularity/NN\n",
            "  understanding/VBG\n",
            "  pattern/JJ\n",
            "  ev/JJ\n",
            "  user/NN\n",
            "  behavior/NN\n",
            "  imperative/JJ\n",
            "  paper/NN\n",
            "  examines/NNS\n",
            "  trend/NN\n",
            "  household/NN\n",
            "  charging/VBG\n",
            "  session/NN\n",
            "  timing/VBG\n",
            "  duration/NN\n",
            "  energy/NN\n",
            "  consumption/NN\n",
            "  analyzing/VBG\n",
            "  real/JJ\n",
            "  world/NN\n",
            "  residential/JJ\n",
            "  charging/VBG\n",
            "  data/NNS\n",
            "  leveraging/VBG\n",
            "  information/NN\n",
            "  collected/VBN\n",
            "  session/NN\n",
            "  novel/NN\n",
            "  framework/NN\n",
            "  introduced/VBD\n",
            "  efficient/JJ\n",
            "  real/JJ\n",
            "  time/NN\n",
            "  prediction/NN\n",
            "  important/JJ\n",
            "  charging/VBG\n",
            "  characteristic/JJ\n",
            "  utilizing/JJ\n",
            "  historical/JJ\n",
            "  data/NNS\n",
            "  user/NN\n",
            "  specific/JJ\n",
            "  feature/NN\n",
            "  machine/NN\n",
            "  learning/VBG\n",
            "  model/NN\n",
            "  trained/VBD\n",
            "  predict/JJ\n",
            "  connection/NN\n",
            "  duration/NN\n",
            "  charging/VBG\n",
            "  duration/NN\n",
            "  charging/VBG\n",
            "  demand/NN\n",
            "  time/NN\n",
            "  next/JJ\n",
            "  session/NN\n",
            "  model/NN\n",
            "  enhance/NN\n",
            "  understanding/VBG\n",
            "  ev/CC\n",
            "  user/JJ\n",
            "  behavior/NN\n",
            "  provide/VBP\n",
            "  practical/JJ\n",
            "  tool/NN\n",
            "  optimizing/VBG\n",
            "  ev/JJ\n",
            "  charging/VBG\n",
            "  infrastructure/NN\n",
            "  effectively/RB\n",
            "  managing/VBG\n",
            "  charging/VBG\n",
            "  demand/NN\n",
            "  transportation/NN\n",
            "  sector/NN\n",
            "  becomes/VBZ\n",
            "  increasingly/RB\n",
            "  electrified/JJ\n",
            "  work/NN\n",
            "  aim/NN\n",
            "  empower/VB\n",
            "  stakeholder/NN\n",
            "  insight/NN\n",
            "  reliable/JJ\n",
            "  model/NN\n",
            "  enabling/VBG\n",
            "  anticipate/JJ\n",
            "  localized/VBN\n",
            "  demand/NN\n",
            "  contribute/NN\n",
            "  sustainable/JJ\n",
            "  integration/NN\n",
            "  electric/JJ\n",
            "  vehicle/NN\n",
            "  grid/NN)\n",
            "\n",
            "==============================\n",
            "PART (2) DEPENDENCY PARSE (spaCy)\n",
            "==============================\n",
            "era             --> vehicle         (nmod)\n",
            "burgeoning      --> vehicle         (amod)\n",
            "electric        --> vehicle         (amod)\n",
            "vehicle         --> collected       (nsubj)\n",
            "ev              --> vehicle         (prep)\n",
            "popularity      --> understanding   (compound)\n",
            "understanding   --> pattern         (compound)\n",
            "pattern         --> ev              (pobj)\n",
            "ev              --> vehicle         (prep)\n",
            "user            --> behavior        (compound)\n",
            "behavior        --> ev              (pobj)\n",
            "imperative      --> paper           (amod)\n",
            "paper           --> examines        (compound)\n",
            "examines        --> session         (compound)\n",
            "trend           --> session         (compound)\n",
            "household       --> charging        (compound)\n",
            "charging        --> session         (compound)\n",
            "session         --> vehicle         (appos)\n",
            "timing          --> session         (acl)\n",
            "duration        --> consumption     (compound)\n",
            "energy          --> consumption     (compound)\n",
            "consumption     --> timing          (dobj)\n",
            "analyzing       --> session         (acl)\n",
            "real            --> world           (amod)\n",
            "world           --> residential     (compound)\n",
            "residential     --> analyzing       (dobj)\n",
            "charging        --> session         (acl)\n",
            "data            --> charging        (dobj)\n",
            "leveraging      --> data            (acl)\n",
            "information     --> collected       (npadvmod)\n",
            "collected       --> framework       (amod)\n",
            "session         --> novel           (compound)\n",
            "novel           --> framework       (amod)\n",
            "framework       --> introduced      (nsubj)\n",
            "introduced      --> introduced      (ROOT)\n",
            "efficient       --> prediction      (amod)\n",
            "real            --> time            (amod)\n",
            "time            --> prediction      (compound)\n",
            "prediction      --> introduced      (dobj)\n",
            "important       --> prediction      (amod)\n",
            "charging        --> introduced      (advcl)\n",
            "characteristic  --> utilizing       (amod)\n",
            "utilizing       --> model           (amod)\n",
            "historical      --> machine         (amod)\n",
            "data            --> user            (compound)\n",
            "user            --> machine         (nmod)\n",
            "specific        --> machine         (amod)\n",
            "feature         --> machine         (compound)\n",
            "machine         --> model           (compound)\n",
            "learning        --> model           (compound)\n",
            "model           --> charging        (dobj)\n",
            "trained         --> duration        (amod)\n",
            "predict         --> duration        (amod)\n",
            "connection      --> duration        (compound)\n",
            "duration        --> model           (appos)\n",
            "charging        --> duration        (acl)\n",
            "duration        --> charging        (compound)\n",
            "charging        --> time            (amod)\n",
            "demand          --> time            (compound)\n",
            "time            --> charging        (dobj)\n",
            "next            --> enhance         (amod)\n",
            "session         --> model           (compound)\n",
            "model           --> enhance         (compound)\n",
            "enhance         --> understanding   (compound)\n",
            "understanding   --> provide         (nsubj)\n",
            "ev              --> understanding   (prep)\n",
            "user            --> behavior        (compound)\n",
            "behavior        --> ev              (pobj)\n",
            "provide         --> introduced      (advcl)\n",
            "practical       --> tool            (amod)\n",
            "tool            --> provide         (dobj)\n",
            "optimizing      --> tool            (acl)\n",
            "ev              --> optimizing      (prep)\n",
            "charging        --> ev              (pcomp)\n",
            "infrastructure  --> charging        (dobj)\n",
            "effectively     --> managing        (advmod)\n",
            "managing        --> ev              (pcomp)\n",
            "charging        --> sector          (amod)\n",
            "demand          --> sector          (compound)\n",
            "transportation  --> sector          (compound)\n",
            "sector          --> managing        (dobj)\n",
            "becomes         --> introduced      (conj)\n",
            "increasingly    --> electrified     (advmod)\n",
            "electrified     --> aim             (amod)\n",
            "work            --> aim             (compound)\n",
            "aim             --> empower         (compound)\n",
            "empower         --> becomes         (acomp)\n",
            "stakeholder     --> insight         (compound)\n",
            "insight         --> empower         (dobj)\n",
            "reliable        --> model           (amod)\n",
            "model           --> introduced      (dobj)\n",
            "enabling        --> demand          (amod)\n",
            "anticipate      --> demand          (nmod)\n",
            "localized       --> demand          (amod)\n",
            "demand          --> contribute      (nsubj)\n",
            "contribute      --> contribute      (ROOT)\n",
            "sustainable     --> grid            (amod)\n",
            "integration     --> vehicle         (nmod)\n",
            "electric        --> vehicle         (compound)\n",
            "vehicle         --> grid            (compound)\n",
            "grid            --> contribute      (dobj)\n",
            "\n",
            "==============================\n",
            "EXPLANATION (One sentence)\n",
            "==============================\n",
            "Constituency tree groups words into nested phrase units (hierarchical structure).\n",
            "Dependency tree links each word to a head word and labels the grammatical relation (subject, object, modifier).\n",
            "\n",
            "==============================\n",
            "PART (3) NER ENTITY COUNTS (by type)\n",
            "==============================\n",
            "Processed rows: 1000\n",
            "CARDINAL  : 528\n",
            "ORG       : 515\n",
            "PERSON    : 436\n",
            "DATE      : 195\n",
            "GPE       : 182\n",
            "ORDINAL   : 164\n",
            "NORP      : 128\n",
            "TIME      : 21\n",
            "LOC       : 15\n",
            "PRODUCT   : 13\n",
            "LANGUAGE  : 12\n",
            "QUANTITY  : 8\n",
            "FAC       : 4\n",
            "PERCENT   : 2\n",
            "WORK_OF_ART: 1\n",
            "\n",
            "Top 20 entity strings:\n",
            "two                            153\n",
            "three                          110\n",
            "one                            88\n",
            "first                          78\n",
            "cnn                            61\n",
            "second                         44\n",
            "four                           36\n",
            "five                           34\n",
            "english                        26\n",
            "recent year                    23\n",
            "six                            20\n",
            "machine svm                    17\n",
            "china                          16\n",
            "daily                          16\n",
            "vector                         15\n",
            "third                          14\n",
            "eight                          14\n",
            "arabic                         14\n",
            "firstly                        13\n",
            "today                          12\n",
            "\n",
            "✅ Saved NER counts file: ner_entity_type_counts.csv\n"
          ]
        }
      ],
      "source": [
        "!pip -q install pandas spacy nltk\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download(\"maxent_ne_chunker_tab\")\n",
        "nltk.download(\"words\")\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.chunk import ne_chunk\n",
        "\n",
        "\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "CLEAN_CSV = \"semantic_scholar_machine_learning_10000_cleaned.csv\"\n",
        "TEXT_COL = \"clean_text\"\n",
        "\n",
        "df = pd.read_csv(CLEAN_CSV)\n",
        "df[TEXT_COL] = df[TEXT_COL].fillna(\"\").astype(str)\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "example_sentence = None\n",
        "for text in df[TEXT_COL].head(200):\n",
        "    if text.strip():\n",
        "        sents = sent_tokenize(text)\n",
        "        if sents:\n",
        "            example_sentence = sents[0]\n",
        "            break\n",
        "\n",
        "if not example_sentence:\n",
        "    raise ValueError(\"No valid clean_text sentence found. Check your CSV.\")\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"EXAMPLE SENTENCE (used for parsing)\")\n",
        "print(\"==============================\")\n",
        "print(example_sentence)\n",
        "\n",
        "\n",
        "N_ROWS = 1000\n",
        "texts_for_pos = df[TEXT_COL].head(N_ROWS).tolist()\n",
        "\n",
        "noun_tags = {\"NN\", \"NNS\", \"NNP\", \"NNPS\"}\n",
        "verb_tags = {\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"}\n",
        "adj_tags  = {\"JJ\", \"JJR\", \"JJS\"}\n",
        "adv_tags  = {\"RB\", \"RBR\", \"RBS\"}\n",
        "\n",
        "noun_count = verb_count = adj_count = adv_count = 0\n",
        "\n",
        "for txt in texts_for_pos:\n",
        "    tokens = word_tokenize(txt)\n",
        "    tags = pos_tag(tokens)\n",
        "    for _, t in tags:\n",
        "        if t in noun_tags:\n",
        "            noun_count += 1\n",
        "        elif t in verb_tags:\n",
        "            verb_count += 1\n",
        "        elif t in adj_tags:\n",
        "            adj_count += 1\n",
        "        elif t in adv_tags:\n",
        "            adv_count += 1\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"PART (1) POS TAGGING COUNTS\")\n",
        "print(\"==============================\")\n",
        "print(\"Processed rows:\", N_ROWS)\n",
        "print(\"Total Nouns:\", noun_count)\n",
        "print(\"Total Verbs:\", verb_count)\n",
        "print(\"Total Adjectives:\", adj_count)\n",
        "print(\"Total Adverbs:\", adv_count)\n",
        "\n",
        "print(\"\\nPOS tags for example sentence:\")\n",
        "ex_tokens = word_tokenize(example_sentence)\n",
        "ex_pos = pos_tag(ex_tokens)\n",
        "print(ex_pos)\n",
        "\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"PART (2) CONSTITUENCY TREE (NLTK ne_chunk Tree)\")\n",
        "print(\"==============================\")\n",
        "chunk_tree = ne_chunk(ex_pos)\n",
        "print(chunk_tree)\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"PART (2) DEPENDENCY PARSE (spaCy)\")\n",
        "print(\"==============================\")\n",
        "doc_sent = nlp(example_sentence)\n",
        "for token in doc_sent:\n",
        "    if token.is_space:\n",
        "        continue\n",
        "    print(f\"{token.text:<15} --> {token.head.text:<15} ({token.dep_})\")\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"EXPLANATION (One sentence)\")\n",
        "print(\"==============================\")\n",
        "print(\"Constituency tree groups words into nested phrase units (hierarchical structure).\")\n",
        "print(\"Dependency tree links each word to a head word and labels the grammatical relation (subject, object, modifier).\")\n",
        "\n",
        "\n",
        "N_ROWS_NER = 1000\n",
        "texts_for_ner = df[TEXT_COL].head(N_ROWS_NER).tolist()\n",
        "\n",
        "entity_type_counts = Counter()\n",
        "entity_text_counts = Counter()\n",
        "\n",
        "for doc in nlp.pipe(texts_for_ner, batch_size=30):\n",
        "    for ent in doc.ents:\n",
        "        entity_type_counts[ent.label_] += 1\n",
        "        entity_text_counts[ent.text] += 1\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"PART (3) NER ENTITY COUNTS (by type)\")\n",
        "print(\"==============================\")\n",
        "print(\"Processed rows:\", N_ROWS_NER)\n",
        "for label, cnt in entity_type_counts.most_common():\n",
        "    print(f\"{label:<10}: {cnt}\")\n",
        "\n",
        "print(\"\\nTop 20 entity strings:\")\n",
        "for ent, cnt in entity_text_counts.most_common(20):\n",
        "    print(f\"{ent:<30} {cnt}\")\n",
        "\n",
        "\n",
        "ner_df = pd.DataFrame(entity_type_counts.items(), columns=[\"entity_type\", \"count\"]).sort_values(\"count\", ascending=False)\n",
        "ner_df.to_csv(\"ner_entity_type_counts.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Saved NER counts file: ner_entity_type_counts.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"ner_entity_type_counts.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2-HhoR5Ygx5p",
        "outputId": "ea58492e-1028-42ef-cc8c-8bd4e80a8964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d2bf319-9d6c-4220-a1b3-6be8fa6a7a2a\", \"ner_entity_type_counts.csv\", 167)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Following Questions must answer using AI assitance**"
      ],
      "metadata": {
        "id": "EcVqy1yj3wja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4 (20 points)."
      ],
      "metadata": {
        "id": "kEdcyHX8VaDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. (PART-1)\n",
        "Web scraping data from the GitHub Marketplace to gather details about popular actions. Using Python, the process begins by sending HTTP requests to multiple pages of the marketplace (1000 products), handling pagination through dynamic page numbers. The key details extracted include the product name, a short description, and the URL.\n",
        "\n",
        " The extracted data is stored in a structured CSV format with columns for product name, description, URL, and page number. A time delay is introduced between requests to avoid server overload. ChatGPT can assist by helping with the parsing of HTML, error handling, and generating reports based on the data collected.\n",
        "\n",
        " The goal is to complete the scraping within a specified time limit, ensuring that the process is efficient and adheres to GitHub’s usage guidelines.\n",
        "\n",
        "(PART -2)\n",
        "\n",
        "1.   **Preprocess Data**: Clean the text by tokenizing, removing stopwords, and converting to lowercase.\n",
        "\n",
        "2. Perform **Data Quality** operations.\n",
        "\n",
        "\n",
        "Preprocessing:\n",
        "Preprocessing involves cleaning the text by removing noise such as special characters, HTML tags, and unnecessary whitespace. It also includes tasks like tokenization, stopword removal, and lemmatization to standardize the text for analysis.\n",
        "\n",
        "Data Quality:\n",
        "Data quality checks ensure completeness, consistency, and accuracy by verifying that all required columns are filled and formatted correctly. Additionally, it involves identifying and removing duplicates, handling missing values, and ensuring the data reflects the true content accurately.\n"
      ],
      "metadata": {
        "id": "1Ung5_YW3C6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part - 1"
      ],
      "metadata": {
        "id": "4vy2iJtF6prX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github MarketPlace page:\n",
        "https://github.com/marketplace?type=actions"
      ],
      "metadata": {
        "id": "CTOfUpatronW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install requests beautifulsoup4 pandas tqdm\n",
        "\n",
        "import time, re, requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm.auto import tqdm\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "BASE = \"https://github.com\"\n",
        "MARKET_URL = \"https://github.com/marketplace\"\n",
        "\n",
        "TYPE = \"actions\"\n",
        "SORT = \"popularity\"\n",
        "TARGET_N = 1000\n",
        "SLEEP_SECONDS = 1.2\n",
        "MAX_PAGES = 600\n",
        "\n",
        "OUT_CSV = \"github_marketplace_actions_1000.csv\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
        "}\n",
        "\n",
        "def clean_ws(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip()\n",
        "\n",
        "def fetch_page(page_num: int, max_retries: int = 6):\n",
        "    params = {\"type\": TYPE, \"sort\": SORT, \"page\": page_num}\n",
        "    backoff = 1.0\n",
        "    for _ in range(max_retries):\n",
        "        try:\n",
        "            r = requests.get(MARKET_URL, params=params, headers=HEADERS, timeout=30)\n",
        "            if r.status_code == 200:\n",
        "                return r.text\n",
        "            if r.status_code in (429, 500, 502, 503, 504):\n",
        "                time.sleep(backoff)\n",
        "                backoff = min(backoff * 2, 30)\n",
        "                continue\n",
        "            print(f\"HTTP {r.status_code} on page {page_num}\")\n",
        "            return None\n",
        "        except requests.RequestException:\n",
        "            time.sleep(backoff)\n",
        "            backoff = min(backoff * 2, 30)\n",
        "    return None\n",
        "\n",
        "def parse_actions(html: str, page_num: int):\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    rows = []\n",
        "    seen = set()\n",
        "\n",
        "\n",
        "    anchors = soup.select('a[href^=\"/marketplace/actions/\"]')\n",
        "\n",
        "    for a in anchors:\n",
        "        href = (a.get(\"href\") or \"\").strip()\n",
        "        name = clean_ws(a.get_text(\" \", strip=True))\n",
        "        if not href or not name:\n",
        "            continue\n",
        "\n",
        "        key = (href, name.lower())\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "\n",
        "        full_url = urljoin(BASE, href)\n",
        "\n",
        "\n",
        "        desc = \"\"\n",
        "        container = a.find_parent([\"li\", \"article\", \"div\", \"section\"])\n",
        "        if container:\n",
        "            p = container.find(\"p\")\n",
        "            if p:\n",
        "                desc = clean_ws(p.get_text(\" \", strip=True))\n",
        "\n",
        "        rows.append({\n",
        "            \"product_name\": name,\n",
        "            \"description\": desc,\n",
        "            \"url\": full_url,\n",
        "            \"page_number\": page_num\n",
        "        })\n",
        "\n",
        "\n",
        "    uniq = {}\n",
        "    for r in rows:\n",
        "        uniq[r[\"url\"]] = r\n",
        "    return list(uniq.values())\n",
        "\n",
        "all_rows = []\n",
        "seen_urls = set()\n",
        "\n",
        "pbar = tqdm(total=TARGET_N, desc=\"Scraping actions\", unit=\"action\")\n",
        "\n",
        "for page in range(1, MAX_PAGES + 1):\n",
        "    if len(seen_urls) >= TARGET_N:\n",
        "        break\n",
        "\n",
        "    html = fetch_page(page)\n",
        "    if not html:\n",
        "        time.sleep(SLEEP_SECONDS)\n",
        "        continue\n",
        "\n",
        "    page_rows = parse_actions(html, page)\n",
        "\n",
        "    for row in page_rows:\n",
        "        if len(seen_urls) >= TARGET_N:\n",
        "            break\n",
        "        if row[\"url\"] in seen_urls:\n",
        "            continue\n",
        "        seen_urls.add(row[\"url\"])\n",
        "        all_rows.append(row)\n",
        "        pbar.update(1)\n",
        "\n",
        "    time.sleep(SLEEP_SECONDS)\n",
        "\n",
        "pbar.close()\n",
        "\n",
        "df_actions = pd.DataFrame(all_rows)\n",
        "df_actions.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n✅ PART-1 COMPLETE\")\n",
        "print(\"Total actions collected:\", len(df_actions))\n",
        "print(\"Saved CSV:\", OUT_CSV)\n",
        "\n",
        "df_actions.head(10)"
      ],
      "metadata": {
        "id": "4dtco9K--ks6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "2e292b5310634da48372327deb33abe3",
            "855d7b958682442da6a130db05f21ac1",
            "3d5f9c8704484c02a69e04665a9ce17f",
            "b2679ddd51c24e7f822be380dbb600ff",
            "76d4c352bb564a5182a0130c29dea499",
            "6c9a414bf9dd4595ac44ee0dc0f08d6c",
            "8e2112ec19bd4e40949e181c2cde6bdd",
            "f4b7feef8933457ebec624bd49a16fc6",
            "b69b1efec9ef4ce28e0e5588a71136e3",
            "ee5483c4cd4e4fef9917d4e4afb91c07",
            "1f35441de51f45a6a6e021295f050250"
          ]
        },
        "outputId": "9fb06e6d-a34b-48af-a07a-0eb631881726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Scraping actions:   0%|          | 0/1000 [00:00<?, ?action/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e292b5310634da48372327deb33abe3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ PART-1 COMPLETE\n",
            "Total actions collected: 1000\n",
            "Saved CSV: github_marketplace_actions_1000.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             product_name description  \\\n",
              "0                          TruffleHog OSS               \n",
              "1                           Metrics embed               \n",
              "2            yq - portable yaml processor               \n",
              "3                            Super-Linter               \n",
              "4              Rebuild Armbian and Kernel               \n",
              "5                  Gosec Security Checker               \n",
              "6                                Checkout               \n",
              "7  OpenCommit — improve commits with AI 🧙               \n",
              "8                     SSH Remote Commands               \n",
              "9             Claude Code Action Official               \n",
              "\n",
              "                                                 url  page_number  \n",
              "0  https://github.com/marketplace/actions/truffle...            1  \n",
              "1  https://github.com/marketplace/actions/metrics...            1  \n",
              "2  https://github.com/marketplace/actions/yq-port...            1  \n",
              "3  https://github.com/marketplace/actions/super-l...            1  \n",
              "4  https://github.com/marketplace/actions/rebuild...            1  \n",
              "5  https://github.com/marketplace/actions/gosec-s...            1  \n",
              "6    https://github.com/marketplace/actions/checkout            1  \n",
              "7  https://github.com/marketplace/actions/opencom...            1  \n",
              "8  https://github.com/marketplace/actions/ssh-rem...            1  \n",
              "9  https://github.com/marketplace/actions/claude-...            1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2060f1ec-a625-49b6-ab2d-22f106cf82a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "      <th>page_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TruffleHog OSS</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/truffle...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Metrics embed</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/metrics...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yq - portable yaml processor</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/yq-port...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super-Linter</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/super-l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rebuild Armbian and Kernel</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/rebuild...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gosec Security Checker</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/gosec-s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Checkout</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/checkout</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OpenCommit — improve commits with AI 🧙</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/opencom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SSH Remote Commands</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/ssh-rem...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Claude Code Action Official</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/claude-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2060f1ec-a625-49b6-ab2d-22f106cf82a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2060f1ec-a625-49b6-ab2d-22f106cf82a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2060f1ec-a625-49b6-ab2d-22f106cf82a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_actions",
              "summary": "{\n  \"name\": \"df_actions\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"product_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"OSKAR-PHP-CS-Fixer\",\n          \"Docker Scout\",\n          \"docker-image-size-limit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"https://github.com/marketplace/actions/oskar-php-cs-fixer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 51,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2"
      ],
      "metadata": {
        "id": "gb3YwR9e7Bli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pandas nltk beautifulsoup4\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "INPUT_CSV = \"github_marketplace_actions_1000.csv\"\n",
        "CLEAN_CSV = \"github_marketplace_actions_1000_cleaned.csv\"\n",
        "QUALITY_CSV = \"github_marketplace_actions_quality_report.csv\"\n",
        "\n",
        "df = pd.read_csv(INPUT_CSV).fillna(\"\")\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def remove_html(text: str) -> str:\n",
        "    return BeautifulSoup(text, \"html.parser\").get_text(\" \")\n",
        "\n",
        "def remove_noise(text: str) -> str:\n",
        "    text = remove_html(str(text))\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text: str):\n",
        "    \"\"\"\n",
        "    Clean noise -> lowercase -> tokenize -> remove stopwords -> lemmatize\n",
        "    Returns tokens list.\n",
        "    \"\"\"\n",
        "    text = remove_noise(text).lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t not in STOPWORDS]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "df[\"product_name_tokens\"] = df[\"product_name\"].apply(preprocess_text)\n",
        "df[\"description_tokens\"]  = df[\"description\"].apply(preprocess_text)\n",
        "\n",
        "df[\"product_name_clean\"] = df[\"product_name_tokens\"].apply(lambda x: \" \".join(x))\n",
        "df[\"description_clean\"]  = df[\"description_tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "print(\"\\nPreview after preprocessing:\")\n",
        "df[[\"product_name\", \"product_name_clean\", \"description\", \"description_clean\"]].head(5)\n",
        "\n",
        "quality = {}\n",
        "\n",
        "\n",
        "quality[\"missing_product_name\"] = int((df[\"product_name\"].str.strip() == \"\").sum())\n",
        "quality[\"missing_description\"]  = int((df[\"description\"].str.strip() == \"\").sum())\n",
        "quality[\"missing_url\"]          = int((df[\"url\"].str.strip() == \"\").sum())\n",
        "quality[\"missing_page_number\"]  = int(df[\"page_number\"].isna().sum())\n",
        "\n",
        "\n",
        "quality[\"duplicate_urls\"]  = int(df.duplicated(subset=[\"url\"]).sum())\n",
        "quality[\"duplicate_names\"] = int(df.duplicated(subset=[\"product_name\"]).sum())\n",
        "\n",
        "\n",
        "quality[\"invalid_url_format\"] = int((~df[\"url\"].astype(str).str.startswith(\"https://github.com/marketplace/actions/\")).sum())\n",
        "\n",
        "\n",
        "quality[\"very_short_names(<3chars)\"] = int((df[\"product_name\"].astype(str).str.len() < 3).sum())\n",
        "quality[\"very_short_desc(<10chars)\"] = int((df[\"description\"].astype(str).str.len() < 10).sum())\n",
        "\n",
        "quality_df = pd.DataFrame(list(quality.items()), columns=[\"check\", \"count\"]).sort_values(\"count\", ascending=False)\n",
        "quality_df.to_csv(QUALITY_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n✅ Data Quality Report:\")\n",
        "display(quality_df)\n",
        "\n",
        "\n",
        "df = df.drop_duplicates(subset=[\"url\"]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "df.to_csv(CLEAN_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n✅ PART-2 COMPLETE\")\n",
        "print(\"Saved cleaned CSV:\", CLEAN_CSV)\n",
        "print(\"Saved quality report CSV:\", QUALITY_CSV)\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "SPWJT78EkE__",
        "outputId": "ae744d28-0fa1-4739-97c0-036e248e5a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 1000\n",
            "Columns: ['product_name', 'description', 'url', 'page_number']\n",
            "\n",
            "Preview after preprocessing:\n",
            "\n",
            "✅ Data Quality Report:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       check  count\n",
              "1        missing_description   1000\n",
              "8  very_short_desc(<10chars)   1000\n",
              "0       missing_product_name      0\n",
              "3        missing_page_number      0\n",
              "2                missing_url      0\n",
              "4             duplicate_urls      0\n",
              "5            duplicate_names      0\n",
              "6         invalid_url_format      0\n",
              "7  very_short_names(<3chars)      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ed0e5fb-cd4c-4fe2-9227-8f94a1a8d1c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>check</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>missing_description</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>very_short_desc(&lt;10chars)</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>missing_product_name</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>missing_page_number</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>missing_url</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>duplicate_urls</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>duplicate_names</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>invalid_url_format</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>very_short_names(&lt;3chars)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ed0e5fb-cd4c-4fe2-9227-8f94a1a8d1c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ed0e5fb-cd4c-4fe2-9227-8f94a1a8d1c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ed0e5fb-cd4c-4fe2-9227-8f94a1a8d1c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_2d9f4a97-9c4f-435d-a9e4-f8fd346c0efc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('quality_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2d9f4a97-9c4f-435d-a9e4-f8fd346c0efc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('quality_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "quality_df",
              "summary": "{\n  \"name\": \"quality_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"check\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"invalid_url_format\",\n          \"very_short_desc(<10chars)\",\n          \"duplicate_urls\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 440,\n        \"min\": 0,\n        \"max\": 1000,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ PART-2 COMPLETE\n",
            "Saved cleaned CSV: github_marketplace_actions_1000_cleaned.csv\n",
            "Saved quality report CSV: github_marketplace_actions_quality_report.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   product_name description  \\\n",
              "0                TruffleHog OSS               \n",
              "1                 Metrics embed               \n",
              "2  yq - portable yaml processor               \n",
              "3                  Super-Linter               \n",
              "4    Rebuild Armbian and Kernel               \n",
              "\n",
              "                                                 url  page_number  \\\n",
              "0  https://github.com/marketplace/actions/truffle...            1   \n",
              "1  https://github.com/marketplace/actions/metrics...            1   \n",
              "2  https://github.com/marketplace/actions/yq-port...            1   \n",
              "3  https://github.com/marketplace/actions/super-l...            1   \n",
              "4  https://github.com/marketplace/actions/rebuild...            1   \n",
              "\n",
              "               product_name_tokens description_tokens  \\\n",
              "0                 [trufflehog, os]                 []   \n",
              "1                  [metric, embed]                 []   \n",
              "2  [yq, portable, yaml, processor]                 []   \n",
              "3                  [super, linter]                 []   \n",
              "4       [rebuild, armbian, kernel]                 []   \n",
              "\n",
              "           product_name_clean description_clean  \n",
              "0               trufflehog os                    \n",
              "1                metric embed                    \n",
              "2  yq portable yaml processor                    \n",
              "3                super linter                    \n",
              "4      rebuild armbian kernel                    "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-989c2029-4a0d-4577-82d4-bfb32506c727\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "      <th>page_number</th>\n",
              "      <th>product_name_tokens</th>\n",
              "      <th>description_tokens</th>\n",
              "      <th>product_name_clean</th>\n",
              "      <th>description_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TruffleHog OSS</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/truffle...</td>\n",
              "      <td>1</td>\n",
              "      <td>[trufflehog, os]</td>\n",
              "      <td>[]</td>\n",
              "      <td>trufflehog os</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Metrics embed</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/metrics...</td>\n",
              "      <td>1</td>\n",
              "      <td>[metric, embed]</td>\n",
              "      <td>[]</td>\n",
              "      <td>metric embed</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yq - portable yaml processor</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/yq-port...</td>\n",
              "      <td>1</td>\n",
              "      <td>[yq, portable, yaml, processor]</td>\n",
              "      <td>[]</td>\n",
              "      <td>yq portable yaml processor</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super-Linter</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/super-l...</td>\n",
              "      <td>1</td>\n",
              "      <td>[super, linter]</td>\n",
              "      <td>[]</td>\n",
              "      <td>super linter</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rebuild Armbian and Kernel</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/rebuild...</td>\n",
              "      <td>1</td>\n",
              "      <td>[rebuild, armbian, kernel]</td>\n",
              "      <td>[]</td>\n",
              "      <td>rebuild armbian kernel</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-989c2029-4a0d-4577-82d4-bfb32506c727')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-989c2029-4a0d-4577-82d4-bfb32506c727 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-989c2029-4a0d-4577-82d4-bfb32506c727');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"product_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"OSKAR-PHP-CS-Fixer\",\n          \"Docker Scout\",\n          \"docker-image-size-limit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"https://github.com/marketplace/actions/oskar-php-cs-fixer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 51,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_name_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_name_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 997,\n        \"samples\": [\n          \"set ocaml\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_clean\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5 (20 points)\n",
        "\n",
        "PART 1:\n",
        "Web Scrape  tweets from Twitter using the Tweepy API, specifically targeting hashtags related to subtopics (machine learning or artificial intelligence.)\n",
        "The extracted data includes the tweet ID, username, and text.\n",
        "\n",
        "Part 2:\n",
        "Perform data cleaning procedures\n",
        "\n",
        "A final data quality check ensures the completeness and consistency of the dataset. The cleaned data is then saved into a CSV file for further analysis.\n",
        "\n",
        "\n",
        "**Note**\n",
        "\n",
        "1.   Follow tutorials provided in canvas to obtain api keys. Use ChatGPT to get the code. Make sure the file is downloaded and saved.\n",
        "2.   Make sure you divide GPT code as shown in tutorials, dont make multiple requestes.\n"
      ],
      "metadata": {
        "id": "3WeD70ty3Gui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tweepy pandas"
      ],
      "metadata": {
        "id": "qYRO5Cn8bYwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tweepy\n",
        "\n",
        "\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAHDe7wEAAAAAjKVdVFGx9ZBqxkwaycpPD4x1dwA%3DCN0ThsdVKZtP52ILRnkASDBcEdCijJr5Ro5pB4o5RkibGtTrCC\"\n",
        "\n",
        "client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=True)"
      ],
      "metadata": {
        "id": "s-sqW9Tn1oeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"(#machinelearning OR #artificialintelligence) -is:retweet lang:en\"\n",
        "\n",
        "rows = []\n",
        "next_token = None\n",
        "\n",
        "\n",
        "TOTAL_TO_COLLECT = 300\n",
        "MAX_PER_REQUEST = 100\n",
        "\n",
        "while len(rows) < TOTAL_TO_COLLECT:\n",
        "    resp = client.search_recent_tweets(\n",
        "        query=query,\n",
        "        max_results=min(MAX_PER_REQUEST, TOTAL_TO_COLLECT - len(rows)),\n",
        "        tweet_fields=[\"id\", \"text\", \"author_id\", \"created_at\"],\n",
        "        expansions=[\"author_id\"],\n",
        "        user_fields=[\"username\"],\n",
        "        next_token=next_token\n",
        "    )\n",
        "\n",
        "\n",
        "    if resp.data is None:\n",
        "        break\n",
        "\n",
        "\n",
        "    user_map = {}\n",
        "    if resp.includes and \"users\" in resp.includes:\n",
        "        user_map = {u.id: u.username for u in resp.includes[\"users\"]}\n",
        "\n",
        "\n",
        "    for t in resp.data:\n",
        "        rows.append({\n",
        "            \"tweet_id\": t.id,\n",
        "            \"username\": user_map.get(t.author_id, None),\n",
        "            \"text\": t.text\n",
        "        })\n",
        "\n",
        "\n",
        "    next_token = resp.meta.get(\"next_token\")\n",
        "    if not next_token:\n",
        "        break\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(\"Collected:\", len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "ARVTXSGn1wcr",
        "outputId": "7e296927-db60-4f8e-c742-68d969c73e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected: 300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_id       username  \\\n",
              "0  2028330708771410263      orfonline   \n",
              "1  2028330029038661879   lopezunwired   \n",
              "2  2028329294775177488     axiopistis   \n",
              "3  2028326996103528633        AmyGBai   \n",
              "4  2028326961836085391  Altechongroup   \n",
              "\n",
              "                                                text  \n",
              "0  #AI is rapidly reshaping warfare, evident in #...  \n",
              "1  US military uses Anthropic’s Claude for Iran s...  \n",
              "2  AI literacy matters: Modern AI isn't magic—it'...  \n",
              "3  📘 Word of the Day: Supervised Learning\\n\\nA ma...  \n",
              "4  An AI-generated film has been pulled from AMC ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93a73c72-4272-4d1c-8a1e-4c6e8cb38d1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>username</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028330708771410263</td>\n",
              "      <td>orfonline</td>\n",
              "      <td>#AI is rapidly reshaping warfare, evident in #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2028330029038661879</td>\n",
              "      <td>lopezunwired</td>\n",
              "      <td>US military uses Anthropic’s Claude for Iran s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2028329294775177488</td>\n",
              "      <td>axiopistis</td>\n",
              "      <td>AI literacy matters: Modern AI isn't magic—it'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2028326996103528633</td>\n",
              "      <td>AmyGBai</td>\n",
              "      <td>📘 Word of the Day: Supervised Learning\\n\\nA ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2028326961836085391</td>\n",
              "      <td>Altechongroup</td>\n",
              "      <td>An AI-generated film has been pulled from AMC ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93a73c72-4272-4d1c-8a1e-4c6e8cb38d1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93a73c72-4272-4d1c-8a1e-4c6e8cb38d1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93a73c72-4272-4d1c-8a1e-4c6e8cb38d1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40506355577516,\n        \"min\": 2028198673935368648,\n        \"max\": 2028330708771410263,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          2028236753274806330,\n          2028211350644650187,\n          2028264740271563174\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 195,\n        \"samples\": [\n          \"WollyAi\",\n          \"subhamchand04\",\n          \"frankzanotto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"#TheInterMind says Conscious Light is Data for the Conscious Mind. https://t.co/BXfRQY5coW #ArtificialIntelligence #AI #Consciousness #Philosophy #Engineering\",\n          \"\\ud83d\\udca1 The future of AI is multi-model. Instead of choosing between GPT, Claude, or Gemini, why not route intelligently to each model's strengths? Better results, lower costs, higher reliability. #AIRouting #LLM #ArtificialIntelligence #TechStrategy #Innovation\",\n          \"\\ud83c\\udfa7The Matrix Network PODCAST on Spotify\\ud83c\\udfa7\\n\\n\\ud83d\\udce2SPOTIFY: https://t.co/6Fb7swFXlz\\n\\n#spotify #itunes #applepodcast #podcast #thematrixnetwork #artificialintelligence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"tweets_raw.csv\", index=False)\n",
        "print(\"File saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6eALh2p36GX",
        "outputId": "34c1fc57-f8b3-4617-c4b2-9708dd0ca757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"tweets_raw.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PjqZM4XD4B7Y",
        "outputId": "7060f8ae-492a-4121-dd1d-21ee5297cce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6a4b9ae6-c47f-4d8e-a841-d6a814d6d84b\", \"tweets_raw.csv\", 76076)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "df = pd.read_csv(\"tweets_raw.csv\")\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "df = df.dropna(subset=[\"tweet_id\", \"username\", \"text\"])\n",
        "\n",
        "df[\"tweet_id\"] = df[\"tweet_id\"].astype(str)\n",
        "\n",
        "df[\"clean_text\"] = df[\"text\"].str.replace(r\"http\\S+|www\\.\\S+\", \"\", regex=True)\n",
        "df[\"clean_text\"] = df[\"clean_text\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
        "df[\"clean_text\"] = df[\"clean_text\"].str.strip().str.lower()\n",
        "\n",
        "print(\"Total rows after cleaning:\", len(df))\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "print(\"\\nDuplicate tweet_id count:\", df[\"tweet_id\"].duplicated().sum())\n",
        "print(\"Empty clean_text rows:\", (df[\"clean_text\"].str.len() == 0).sum())\n",
        "\n",
        "df.to_csv(\"tweets_cleaned.csv\", index=False)\n",
        "\n",
        "files.download(\"tweets_cleaned.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "sR9m5Myz4wnl",
        "outputId": "ab78b87b-f0ca-4c40-8790-5375d5653428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows after cleaning: 300\n",
            "\n",
            "Missing values:\n",
            " tweet_id      0\n",
            "username      0\n",
            "text          0\n",
            "clean_text    0\n",
            "dtype: int64\n",
            "\n",
            "Duplicate tweet_id count: 0\n",
            "Empty clean_text rows: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b4da0591-f458-4b10-871b-32f4e4b3826a\", \"tweets_cleaned.csv\", 133159)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question (5 points)\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ],
      "metadata": {
        "id": "q8BFCvWp32cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For me , this assignment was an extensive and practical experience in web scraping, text preprocessing, and natural language processing. The ability to deal with API limitations and compatibility was one of the most difficult points, especially when dealing with various libraries in Google Colab. The patience and debugging abilities were necessary to manage pagination, rate limits, and periodic package dependency errors. Moreover, syntax analysis like constituency and dependency parsing was also technically challenging since it involved both linguistic theory and details of how the tool works.\n",
        "Nevertheless, I found the practicality of the assignment very enjoyable. The practical aspect of learning was achieved through the collection of real-world data on sources such as Semantic Scholar, GitHub Marketplace, and twitter. This preprocessing and data quality process was especially rewarding since it was used to convert unstructured, sloppy data into organized and interpretable data. Another thing that I liked about the assignment was that it combined several NLP tasks: POS tagging, parsing, and named entity recognition, which helped me understand the interaction between various methods in text analytics.\n",
        "\n",
        "As far as the time available to get through with the assignment is concerned, it was decent but demanded regular effort and time management. Due to the fact that the tasks were to be carried out in the API set up, debugging, and processing of large data, the students had to dedicate enough time to testing and troubleshooting. Generally, the assignment itself was well-designed to train the practical skills in both NLP and data engineering, and it was a helpful experience.\n"
      ],
      "metadata": {
        "id": "JbTa-jDS-KFI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e292b5310634da48372327deb33abe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_855d7b958682442da6a130db05f21ac1",
              "IPY_MODEL_3d5f9c8704484c02a69e04665a9ce17f",
              "IPY_MODEL_b2679ddd51c24e7f822be380dbb600ff"
            ],
            "layout": "IPY_MODEL_76d4c352bb564a5182a0130c29dea499"
          }
        },
        "855d7b958682442da6a130db05f21ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c9a414bf9dd4595ac44ee0dc0f08d6c",
            "placeholder": "​",
            "style": "IPY_MODEL_8e2112ec19bd4e40949e181c2cde6bdd",
            "value": "Scraping actions: 100%"
          }
        },
        "3d5f9c8704484c02a69e04665a9ce17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b7feef8933457ebec624bd49a16fc6",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b69b1efec9ef4ce28e0e5588a71136e3",
            "value": 1000
          }
        },
        "b2679ddd51c24e7f822be380dbb600ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee5483c4cd4e4fef9917d4e4afb91c07",
            "placeholder": "​",
            "style": "IPY_MODEL_1f35441de51f45a6a6e021295f050250",
            "value": " 1000/1000 [01:41&lt;00:00, 10.09action/s]"
          }
        },
        "76d4c352bb564a5182a0130c29dea499": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c9a414bf9dd4595ac44ee0dc0f08d6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2112ec19bd4e40949e181c2cde6bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4b7feef8933457ebec624bd49a16fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b69b1efec9ef4ce28e0e5588a71136e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee5483c4cd4e4fef9917d4e4afb91c07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f35441de51f45a6a6e021295f050250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d224577e52a440568201117cd597c989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6263449a4344aedb0713ca326da1ed9",
              "IPY_MODEL_ce354b51b28044c598e39f32790974db",
              "IPY_MODEL_52241b96dadf4d9e9d6cfc40e4592a7a"
            ],
            "layout": "IPY_MODEL_291b0b40f2774d6abeeba5d11b855280"
          }
        },
        "c6263449a4344aedb0713ca326da1ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dbbff4950904ed49c0ad495180776b9",
            "placeholder": "​",
            "style": "IPY_MODEL_715e25b27f6a4281bd58272c64670898",
            "value": "Collected abstracts:  29%"
          }
        },
        "ce354b51b28044c598e39f32790974db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff8c9b583754063b6ffb305fc2b27fb",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba55058cccec4d33a18e2c222566a455",
            "value": 2936
          }
        },
        "52241b96dadf4d9e9d6cfc40e4592a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_125fcee5a2e245fcadb5a7f5e82ec52f",
            "placeholder": "​",
            "style": "IPY_MODEL_7f8c29cb10dc4376b90fd3fb40cce845",
            "value": " 2936/10000 [00:07&lt;00:26, 264.86paper/s]"
          }
        },
        "291b0b40f2774d6abeeba5d11b855280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dbbff4950904ed49c0ad495180776b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "715e25b27f6a4281bd58272c64670898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ff8c9b583754063b6ffb305fc2b27fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba55058cccec4d33a18e2c222566a455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "125fcee5a2e245fcadb5a7f5e82ec52f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f8c29cb10dc4376b90fd3fb40cce845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}