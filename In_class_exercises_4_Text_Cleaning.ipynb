{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjaliAleti/Aleti_INFO5731_Fall2024/blob/main/In_class_exercises_4_Text_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d59ccffd",
      "metadata": {
        "id": "d59ccffd"
      },
      "source": [
        "# In-Class Assignment — Data Preprocessing & Cleaning (Text)  \n",
        "**Time:** 20 minutes  |  **Points:** 10  \n",
        "\n",
        "## Instructions\n",
        "- This is an individual in-class assignment.  \n",
        "- Write your code **inside each answer cell**.  \n",
        "- Print the required outputs.  \n",
        "- Submit your GitHub/Colab link as instructed by the instructor.\n",
        "\n",
        "\n",
        "You are given a small dataset of customer support messages as a **TAB-separated text file**:  \n",
        "- `support_messages.txt`\n",
        "\n",
        "You will download this file from **Canvas** and upload it to your **Google Colab** notebook.\n",
        "\n",
        "**How to upload it to your Google Colab notebook?**\n",
        "\n",
        "1. Download `support_messages.txt` from Canvas.\n",
        "3. In **the left sidebar**, click the **Files** icon (folder).  \n",
        "4. Click **Upload** and select `support_messages.txt`.\n",
        "\n",
        "6. RightAfter uploading, the file will appear in the Colab file list on the left.\n",
        "\n",
        "6. Right-click the file, copy its path, and paste it into the FILE_PATH variable in Q1.\n",
        "\n",
        "7. Run Q1 to load the dataset.\n",
        "\n",
        "\n",
        "\n",
        "> Important: Keep the file name exactly as `support_messages.txt`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b060c82",
      "metadata": {
        "id": "4b060c82"
      },
      "source": [
        "## Questions (Total = 10 points)\n",
        "\n",
        "### Q1 (1 point) — Load the dataset\n",
        "Load the TAB-separated file into a pandas DataFrame with columns: `id`, `message`.  \n",
        "Print: **(a)** `df.shape`, **(b)** `df.head(3)`.\n",
        "\n",
        "### Q2 (3 points) — Descriptive columns\n",
        "Add these columns for each message and print the full DataFrame:\n",
        "- `word_count`: number of words  \n",
        "- `char_count`: number of characters  \n",
        "- `num_count`: number of digits (0–9)  \n",
        "- `upper_word_count`: number of ALL-CAPS words (e.g., `\"WHY\"`, `\"DAMAGED\"`)  \n",
        "\n",
        "### Q3 (3 points) — Clean text\n",
        "Build a `clean_text(text)` function and create a new column `clean` with these steps **in order**:\n",
        "1) lowercase  \n",
        "2) remove punctuation/symbols (keep letters/numbers/spaces)  \n",
        "3) remove English stopwords (use **nltk** or **sklearn** list)  \n",
        "4) remove extra spaces  \n",
        "\n",
        "Print the **original** message and **clean** version for rows `id=1` and `id=4`.\n",
        "\n",
        "### Q4 (2 points) — Regex extraction\n",
        "Using RegEx, extract and create two new columns:\n",
        "- `order_id`: first occurrence of pattern `ORD-####` (case-insensitive; `ord-1060` is valid)  \n",
        "- `email`: first email address if present (otherwise `None`/`NaN`)  \n",
        "\n",
        "Print: `id`, `order_id`, `email` for all rows.\n",
        "\n",
        "### Q5 (1 point) — TF-IDF keywords\n",
        "Using the `clean` column, compute **TF-IDF** for the messages and print the **top 5 keywords** with the highest **average TF-IDF** across documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d5ab696",
      "metadata": {
        "id": "4d5ab696"
      },
      "outputs": [],
      "source": [
        "# Setup (run this cell first)\n",
        "import re\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98307e5e",
      "metadata": {
        "id": "98307e5e"
      },
      "source": [
        "## Q1 (1 point) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3c4b8a8c",
      "metadata": {
        "id": "3c4b8a8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db75208-e681-4045-9f16-e2e214440802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:\n",
            "(9, 2)\n",
            "\n",
            "First 3 rows:\n",
            "   id                                            message\n",
            "0  id                                            message\n",
            "1   1  Hi!! My ORDER is late :(  Order# ORD-1042. Ema...\n",
            "2   2  Refund please!!! I was charged 2 times... invo...\n"
          ]
        }
      ],
      "source": [
        "# Q1 — ANSWER CELL\n",
        "FILE_PATH = \"/content/support_messages.txt\"\n",
        "\n",
        "# TODO: load the TAB-separated file into df\n",
        "# Hint: pd.read_csv(FILE_PATH, sep=\"\\t\")\n",
        "df = None\n",
        "\n",
        "# TODO: print df.shape and df.head(3)\n",
        "import pandas as pd\n",
        "\n",
        "# Load the TAB-separated file\n",
        "# Replace 'your_file.txt' with your actual file name\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.txt' with your actual file name\n",
        "file_path = '/content/support_messages.txt'\n",
        "\n",
        "# Load TAB-separated file\n",
        "df = pd.read_csv(file_path, sep='\\t', names=['id', 'message'])\n",
        "\n",
        "# (a) Print shape of the DataFrame\n",
        "print(\"Shape of DataFrame:\")\n",
        "print(df.shape)\n",
        "\n",
        "# (b) Print first 3 rows\n",
        "print(\"\\nFirst 3 rows:\")\n",
        "print(df.head(3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97eb3845",
      "metadata": {
        "id": "97eb3845"
      },
      "source": [
        "## Q2 (3 points) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "37d972dc",
      "metadata": {
        "id": "37d972dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fce5c1-00e8-4cc0-a92a-18774f819f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     message  word_count  char_count  num_count  \\\n",
            "0   WHY is this DAMAGED 123?           5          24          3   \n",
            "1           Hello there 4567           3          16          4   \n",
            "2  This is a TEST message 89           6          25          2   \n",
            "\n",
            "   upper_word_count  \n",
            "0                 2  \n",
            "1                 0  \n",
            "2                 1  \n"
          ]
        }
      ],
      "source": [
        "# Q2 — ANSWER CELL\n",
        "# TODO: create word_count, char_count, num_count, upper_word_count\n",
        "# Hint for digits: df[\"message\"].str.count(r\"\\d\")\n",
        "# Hint for ALL-CAPS words: count tokens where token.isupper()\n",
        "\n",
        "# TODO: display/print the full DataFrame\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Sample DataFrame (replace this with your actual data)\n",
        "data = {\n",
        "    \"message\": [\n",
        "        \"WHY is this DAMAGED 123?\",\n",
        "        \"Hello there 4567\",\n",
        "        \"This is a TEST message 89\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Add required columns\n",
        "df[\"word_count\"] = df[\"message\"].apply(lambda x: len(str(x).split()))\n",
        "df[\"char_count\"] = df[\"message\"].apply(lambda x: len(str(x)))\n",
        "df[\"num_count\"] = df[\"message\"].apply(lambda x: sum(c.isdigit() for c in str(x)))\n",
        "df[\"upper_word_count\"] = df[\"message\"].apply(\n",
        "    lambda x: sum(1 for word in str(x).split() if word.isupper())\n",
        ")\n",
        "\n",
        "# Print full DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b289863b",
      "metadata": {
        "id": "b289863b"
      },
      "source": [
        "## Q3 (3 points) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "479efbe4",
      "metadata": {
        "id": "479efbe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04cc3eb-47cc-4afe-a36d-27ce97d77db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                     message                      clean\n",
            "0   1                    WHY is this DAMAGED 123?                damaged 123\n",
            "3   4  I can't believe this product costs $500!!!  believe product costs 500\n"
          ]
        }
      ],
      "source": [
        "# Q3 — ANSWER CELL\n",
        "# Option A (sklearn stopwords):\n",
        "# from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "# STOPWORDS = set(ENGLISH_STOP_WORDS)\n",
        "\n",
        "# Option B (nltk stopwords):\n",
        "# import nltk\n",
        "# nltk.download(\"stopwords\")\n",
        "# from nltk.corpus import stopwords\n",
        "# STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "def clean_text(text: str) -> str:\n",
        "    # TODO: implement steps 1–4 in order\n",
        "    return str(text)\n",
        "\n",
        "# TODO: create df[\"clean\"] using clean_text\n",
        "# TODO: print original and clean for id=1 and id=4\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "# Sample DataFrame (replace with your actual dataset)\n",
        "data = {\n",
        "    \"id\": [1, 2, 3, 4],\n",
        "    \"message\": [\n",
        "        \"WHY is this DAMAGED 123?\",\n",
        "        \"Hello there!!! How are you?\",\n",
        "        \"This is a TEST message 89.\",\n",
        "        \"I can't believe this product costs $500!!!\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Clean text function\n",
        "def clean_text(text):\n",
        "    # 1. Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Remove punctuation/symbols (keep letters, numbers, spaces)\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "\n",
        "    # 3. Remove English stopwords\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in ENGLISH_STOP_WORDS]\n",
        "\n",
        "    # 4. Remove extra spaces\n",
        "    text = \" \".join(words)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Create new column 'clean'\n",
        "df[\"clean\"] = df[\"message\"].apply(clean_text)\n",
        "\n",
        "# Print original and clean version for id = 1 and id = 4\n",
        "print(df[df[\"id\"].isin([1, 4])][[\"id\", \"message\", \"clean\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40778881",
      "metadata": {
        "id": "40778881"
      },
      "source": [
        "## Q4 (2 points) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9bcd6e3b",
      "metadata": {
        "id": "9bcd6e3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9dbcb80-2afe-4abe-dd34-4cf03172c928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id  order_id              email\n",
            "0   1  ORD-1234   support@test.com\n",
            "1   2  ORD-1060   help@company.org\n",
            "2   3      None  user123@gmail.com\n",
            "3   4  ORD-9999               None\n"
          ]
        }
      ],
      "source": [
        "# Q4 — ANSWER CELL\n",
        "# order_id pattern: r\"ORD-\\d{4}\" with re.IGNORECASE\n",
        "# email pattern (simple): r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\"\n",
        "\n",
        "# TODO: create df[\"order_id\"] and df[\"email\"]\n",
        "# TODO: print/display df[[\"id\", \"order_id\", \"email\"]]\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Sample DataFrame (replace with your actual dataset)\n",
        "data = {\n",
        "    \"id\": [1, 2, 3, 4],\n",
        "    \"message\": [\n",
        "        \"Your order ORD-1234 has been shipped. Contact us at support@test.com\",\n",
        "        \"Issue with ord-1060 please email help@company.org\",\n",
        "        \"No order id here but mail me at user123@gmail.com\",\n",
        "        \"Tracking number ORD-9999\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Regex patterns\n",
        "order_pattern = re.compile(r'\\b(ord-\\d{4})\\b', re.IGNORECASE)\n",
        "email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b')\n",
        "\n",
        "# Extract order_id\n",
        "df[\"order_id\"] = df[\"message\"].apply(\n",
        "    lambda x: order_pattern.search(x).group(1).upper()\n",
        "    if order_pattern.search(x) else None\n",
        ")\n",
        "\n",
        "# Extract email\n",
        "df[\"email\"] = df[\"message\"].apply(\n",
        "    lambda x: email_pattern.search(x).group(0)\n",
        "    if email_pattern.search(x) else None\n",
        ")\n",
        "\n",
        "# Print required columns\n",
        "print(df[[\"id\", \"order_id\", \"email\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9417594",
      "metadata": {
        "id": "e9417594"
      },
      "source": [
        "## Q5 (1 point) — Answer below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "77b7114b",
      "metadata": {
        "id": "77b7114b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694753a8-df11-4e51-9691-f16b7a850de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Keywords with Highest Average TF-IDF:\n",
            "\n",
            "123         0.176777\n",
            "damaged     0.176777\n",
            "hello       0.144338\n",
            "9999        0.144338\n",
            "tracking    0.144338\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Q5 — ANSWER CELL\n",
        "# Hint: from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# 1) fit TF-IDF on df[\"clean\"]\n",
        "# 2) compute average TF-IDF per term across documents\n",
        "# 3) print top 5 terms + their average scores\n",
        "\n",
        "# TODO\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Example DataFrame (replace with your actual df)\n",
        "data = {\n",
        "    \"clean\": [\n",
        "        \"damaged 123\",\n",
        "        \"hello test message\",\n",
        "        \"believe product costs 500\",\n",
        "        \"tracking number 9999\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the clean text\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"clean\"])\n",
        "\n",
        "# Convert to DataFrame\n",
        "tfidf_df = pd.DataFrame(\n",
        "    tfidf_matrix.toarray(),\n",
        "    columns=vectorizer.get_feature_names_out()\n",
        ")\n",
        "\n",
        "# Compute average TF-IDF score for each term\n",
        "avg_tfidf = tfidf_df.mean(axis=0)\n",
        "\n",
        "# Get top 5 keywords with highest average TF-IDF\n",
        "top_5 = avg_tfidf.sort_values(ascending=False).head(5)\n",
        "\n",
        "print(\"Top 5 Keywords with Highest Average TF-IDF:\\n\")\n",
        "print(top_5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f2c975",
      "metadata": {
        "id": "e7f2c975"
      },
      "source": [
        "## Grading Checklist\n",
        "- Q1: correct load + prints  \n",
        "- Q2: correct counts  \n",
        "- Q3: cleaning follows the required order + prints for id=1 and id=4  \n",
        "- Q4: regex extraction works (case-insensitive `ORD-####` and emails)  \n",
        "- Q5: prints 5 keywords + their scores (rounding is fine)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}