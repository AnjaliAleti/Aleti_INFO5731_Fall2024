{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjaliAleti/Aleti_INFO5731_Fall2024/blob/main/Aleti_Anjali_Assignment_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryk8D1Q4Wsrp"
      },
      "source": [
        "# **INFO5731 Assignment 1**\n",
        "\n",
        "In this assignment, you will work on gathering text data from an open data source via web scraping or API. Following this, you will need to clean the text data and perform syntactic analysis on the data. Follow the instructions carefully and design well-structured Python programs to address each question.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "* **Make sure to submit the cleaned data CSV in the comment section - 10 points**\n",
        "\n",
        "**Total points**: 100\n",
        "\n",
        "\n",
        "**Late Submission will have a penalty of 10% reduction for each day after the deadline.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkzR8cFAyGik"
      },
      "source": [
        "# Question 1 (25 points)\n",
        "\n",
        "Write a python program to collect text data from **either of the following sources** and save the data into a **csv file:**\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon. [atleast 1000 reviews]\n",
        "\n",
        "(2) Collect the top 1000 User Reviews of a movie recently in 2024 or 2025 (you can choose any movie) from IMDB. [If one movie doesn't have sufficient reviews, collect reviews of atleast 2 or 3 movies]\n",
        "\n",
        "\n",
        "(3) Collect the **abstracts** of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from Semantic Scholar.\n",
        "\n",
        "(4) Collect all the information of the 904 narrators in the Densho Digital Repository.\n",
        "\n",
        "(5)**Collect a total of 10000 reviews** of the top 100 most popular software from G2 and Capterra.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDyTKYs-yGit"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "!pip -q install pandas tqdm requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip -q install pandas tqdm requests\n",
        "\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "API_KEY = \"\"\n",
        "\n",
        "QUERY = \"machine learning\"\n",
        "TARGET_N = 10000\n",
        "SLEEP_SECONDS = 1.1\n",
        "OUT_CSV = f\"semantic_scholar_{QUERY.replace(' ','_')}_{TARGET_N}.csv\"\n",
        "\n",
        "BASE_URL = \"https://api.semanticscholar.org/graph/v1/paper/search/bulk\"\n",
        "FIELDS = \"paperId,title,abstract,year,venue,url,authors\"\n",
        "\n",
        "\n",
        "headers = {}\n",
        "if isinstance(API_KEY, str) and API_KEY.strip():\n",
        "    headers[\"x-api-key\"] = API_KEY.strip()\n",
        "\n",
        "def fetch_with_retries(url, params, headers, max_retries=8):\n",
        "    \"\"\"Robust GET with retries/backoff for rate limits (429) and server errors.\"\"\"\n",
        "    backoff = 1.0\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            r = requests.get(url, params=params, headers=headers, timeout=60)\n",
        "\n",
        "            if r.status_code == 200:\n",
        "                return r.json()\n",
        "\n",
        "            elif r.status_code == 429:\n",
        "\n",
        "                print(f\"429 Rate limit hit. Sleeping {backoff:.1f}s...\")\n",
        "                time.sleep(backoff)\n",
        "                backoff = min(backoff * 2, 60)\n",
        "\n",
        "            elif 500 <= r.status_code < 600:\n",
        "\n",
        "                print(f\"{r.status_code} Server error. Sleeping {backoff:.1f}s...\")\n",
        "                time.sleep(backoff)\n",
        "                backoff = min(backoff * 2, 60)\n",
        "\n",
        "            else:\n",
        "\n",
        "                raise RuntimeError(f\"HTTP {r.status_code}: {r.text[:300]}\")\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            print(\"Request exception:\", e, f\"| Sleeping {backoff:.1f}s...\")\n",
        "            time.sleep(backoff)\n",
        "            backoff = min(backoff * 2, 60)\n",
        "\n",
        "    raise RuntimeError(\"Max retries exceeded (API not responding or rate limited too long).\")\n",
        "\n",
        "\n",
        "all_rows = []\n",
        "seen_ids = set()\n",
        "\n",
        "params = {\n",
        "    \"query\": QUERY,\n",
        "    \"fields\": FIELDS\n",
        "}\n",
        "\n",
        "print(f\"Starting bulk search for query: {QUERY}\")\n",
        "resp = fetch_with_retries(BASE_URL, params=params, headers=headers)\n",
        "\n",
        "estimated_total = resp.get(\"total\", None)\n",
        "if estimated_total is not None:\n",
        "    print(f\"Estimated matches: {estimated_total}\")\n",
        "\n",
        "pbar = tqdm(total=TARGET_N, desc=\"Collected abstracts\", unit=\"paper\")\n",
        "\n",
        "while True:\n",
        "    data = resp.get(\"data\", [])\n",
        "    if not data:\n",
        "        print(\"No more data returned. Stopping.\")\n",
        "        break\n",
        "\n",
        "    for paper in data:\n",
        "        if len(all_rows) >= TARGET_N:\n",
        "            break\n",
        "\n",
        "        pid = paper.get(\"paperId\")\n",
        "        if not pid or pid in seen_ids:\n",
        "            continue\n",
        "\n",
        "        seen_ids.add(pid)\n",
        "\n",
        "        authors = paper.get(\"authors\", [])\n",
        "        author_names = \", \".join([a.get(\"name\", \"\").strip() for a in authors if a.get(\"name\")])\n",
        "\n",
        "        row = {\n",
        "            \"paperId\": pid,\n",
        "            \"title\": paper.get(\"title\", \"\"),\n",
        "            \"abstract\": paper.get(\"abstract\", \"\"),\n",
        "            \"year\": paper.get(\"year\", \"\"),\n",
        "            \"venue\": paper.get(\"venue\", \"\"),\n",
        "            \"url\": paper.get(\"url\", \"\"),\n",
        "            \"authors\": author_names\n",
        "        }\n",
        "\n",
        "        all_rows.append(row)\n",
        "        pbar.update(1)\n",
        "\n",
        "    if len(all_rows) >= TARGET_N:\n",
        "        print(\"Reached TARGET_N. Stopping.\")\n",
        "        break\n",
        "\n",
        "    token = resp.get(\"token\")\n",
        "    if not token:\n",
        "        print(\"No token for next page. Stopping.\")\n",
        "        break\n",
        "\n",
        "    params = {\n",
        "        \"query\": QUERY,\n",
        "        \"fields\": FIELDS,\n",
        "        \"token\": token\n",
        "    }\n",
        "\n",
        "    time.sleep(SLEEP_SECONDS)\n",
        "    resp = fetch_with_retries(BASE_URL, params=params, headers=headers)\n",
        "\n",
        "pbar.close()\n",
        "\n",
        "\n",
        "df = pd.DataFrame(all_rows)\n",
        "df.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(f\"\\n✅ Saved {len(df)} records to: {OUT_CSV}\")\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794,
          "referenced_widgets": [
            "a11b5c153ab249319cc92c6fce2ed9ff",
            "8b1a0c48596345d9bec6c6ff07b3e84f",
            "084b2177d285443084b3a06330d0b50d",
            "6d2e92bced7f4e7882f77ceff1b94b1b",
            "fdfba996045f4a4694698d9d21f64cf0",
            "6022d14e407a47a3915c7645d45d928f",
            "d97c6aa161be4669a1f48f738535ac14",
            "73c5c5bdec034ad98416bfc9b660f8a5",
            "12b497a3d2b4471088fe51c59d086df9",
            "5861860a8e704f7186ad70eb9749f3f9",
            "360aca54cf064bf19fcd40c57408e8bc"
          ]
        },
        "id": "lNlY3o1HZDUH",
        "outputId": "a15aa5d5-d7e7-4526-8a33-6b85542e3c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting bulk search for query: machine learning\n",
            "Estimated matches: 1017265\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Collected abstracts:   0%|          | 0/10000 [00:00<?, ?paper/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a11b5c153ab249319cc92c6fce2ed9ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No token for next page. Stopping.\n",
            "\n",
            "✅ Saved 1836 records to: semantic_scholar_machine_learning_10000.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    paperId  \\\n",
              "0  00000c33779acab142af6c7a6dae8b36fac0805d   \n",
              "1  0000238f07f151172cf2602588ba762b55c8464b   \n",
              "2  00002d31a8c758062a51d9a259313d81a5eaf399   \n",
              "3  0000315635be19f6278dbc72597b3065fac405f0   \n",
              "4  00005d68c6c7eb4d3c27da8242a30b9a498f991e   \n",
              "\n",
              "                                               title  \\\n",
              "0  Insights into Household Electric Vehicle Charg...   \n",
              "1  Personalized Prediction of Response to Smartph...   \n",
              "2  A Machine Learning Method to Quantify the Role...   \n",
              "3  Abstractive text summarization of low-resource...   \n",
              "4  Detection of DDoS Attacks on Clouds Computing ...   \n",
              "\n",
              "                                            abstract    year  \\\n",
              "0  In the era of burgeoning electric vehicle (EV)...  2024.0   \n",
              "1  Background Meditation apps have surged in popu...  2021.0   \n",
              "2                                               None  2020.0   \n",
              "3  Background Humans must be able to cope with th...  2023.0   \n",
              "4  The growing number of cloud-based services has...  2023.0   \n",
              "\n",
              "                                               venue  \\\n",
              "0                                           Energies   \n",
              "1               Journal of Medical Internet Research   \n",
              "2  International Conference on Information System...   \n",
              "3                             PeerJ Computer Science   \n",
              "4  International Conference on Communication and ...   \n",
              "\n",
              "                                                 url  \\\n",
              "0  https://www.semanticscholar.org/paper/00000c33...   \n",
              "1  https://www.semanticscholar.org/paper/0000238f...   \n",
              "2  https://www.semanticscholar.org/paper/00002d31...   \n",
              "3  https://www.semanticscholar.org/paper/00003156...   \n",
              "4  https://www.semanticscholar.org/paper/00005d68...   \n",
              "\n",
              "                                             authors  \n",
              "0  Ahmad Almaghrebi, Kevin James, Fares al Juhesh...  \n",
              "1  Christian A. Webb, M. Hirshberg, R. Davidson, ...  \n",
              "2     L. Szczyrba, Yang Zhang, D. Pamukçu, D. Eroglu  \n",
              "3  Nida Shafiq, Isma Hamid, Muhammad Asif, Qamar ...  \n",
              "4                     Iehab Alrassan, Asma Alqahtani  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ec8e5f9-3180-4def-9ac2-73b3e5e9d81a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paperId</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>year</th>\n",
              "      <th>venue</th>\n",
              "      <th>url</th>\n",
              "      <th>authors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00000c33779acab142af6c7a6dae8b36fac0805d</td>\n",
              "      <td>Insights into Household Electric Vehicle Charg...</td>\n",
              "      <td>In the era of burgeoning electric vehicle (EV)...</td>\n",
              "      <td>2024.0</td>\n",
              "      <td>Energies</td>\n",
              "      <td>https://www.semanticscholar.org/paper/00000c33...</td>\n",
              "      <td>Ahmad Almaghrebi, Kevin James, Fares al Juhesh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0000238f07f151172cf2602588ba762b55c8464b</td>\n",
              "      <td>Personalized Prediction of Response to Smartph...</td>\n",
              "      <td>Background Meditation apps have surged in popu...</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>Journal of Medical Internet Research</td>\n",
              "      <td>https://www.semanticscholar.org/paper/0000238f...</td>\n",
              "      <td>Christian A. Webb, M. Hirshberg, R. Davidson, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00002d31a8c758062a51d9a259313d81a5eaf399</td>\n",
              "      <td>A Machine Learning Method to Quantify the Role...</td>\n",
              "      <td>None</td>\n",
              "      <td>2020.0</td>\n",
              "      <td>International Conference on Information System...</td>\n",
              "      <td>https://www.semanticscholar.org/paper/00002d31...</td>\n",
              "      <td>L. Szczyrba, Yang Zhang, D. Pamukçu, D. Eroglu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0000315635be19f6278dbc72597b3065fac405f0</td>\n",
              "      <td>Abstractive text summarization of low-resource...</td>\n",
              "      <td>Background Humans must be able to cope with th...</td>\n",
              "      <td>2023.0</td>\n",
              "      <td>PeerJ Computer Science</td>\n",
              "      <td>https://www.semanticscholar.org/paper/00003156...</td>\n",
              "      <td>Nida Shafiq, Isma Hamid, Muhammad Asif, Qamar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00005d68c6c7eb4d3c27da8242a30b9a498f991e</td>\n",
              "      <td>Detection of DDoS Attacks on Clouds Computing ...</td>\n",
              "      <td>The growing number of cloud-based services has...</td>\n",
              "      <td>2023.0</td>\n",
              "      <td>International Conference on Communication and ...</td>\n",
              "      <td>https://www.semanticscholar.org/paper/00005d68...</td>\n",
              "      <td>Iehab Alrassan, Asma Alqahtani</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ec8e5f9-3180-4def-9ac2-73b3e5e9d81a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ec8e5f9-3180-4def-9ac2-73b3e5e9d81a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ec8e5f9-3180-4def-9ac2-73b3e5e9d81a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1836,\n  \"fields\": [\n    {\n      \"column\": \"paperId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1836,\n        \"samples\": [\n          \"0026f1f4e06854198098e3eef5f4e3930dcdd3dc\",\n          \"0062f97c48b7879f52843ea9de42eabb558a1569\",\n          \"00694ae9742e30aa244d7d1f32dc99dbafac25d5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1836,\n        \"samples\": [\n          \"Relationship Induced Multi-Template Learning for Diagnosis of Alzheimer\\u2019s Disease and Mild Cognitive Impairment\",\n          \"Martian bow shock and magnetic pileup boundary models based on machine learning\",\n          \"Association between Prefrontal fNIRS signals during Cognitive tasks and College scholastic ability test (CSAT) scores: Analysis using a quantum annealing approach\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1219,\n        \"samples\": [\n          \"Music plays an important role in one's life, the tone of music helps to heal the pain and it also helps to enjoy moments. We have different song lists depending upon the mood. But there are no such tools that can be used as an emotion-based music player that detects the emotion of the person and plays music according to the mood. The proposed system is Emotion Based Music Player using Python and Machine Learning.\",\n          \"Abstract Background Artificial intelligence (AI) and machine learning (ML) are poised to transform infectious disease testing. Uniquely, infectious disease testing is technologically diverse spaces in laboratory medicine, where multiple platforms and approaches may be required to support clinical decision-making. Despite advances in laboratory informatics, the vast array of infectious disease data is constrained by human analytical limitations. Machine learning can exploit multiple data streams, including but not limited to laboratory information and overcome human limitations to provide physicians with predictive and actionable results. As a quickly evolving area of computer science, laboratory professionals should become aware of AI/ML applications for infectious disease testing as more platforms are become commercially available. Content In this review we: (a) define both AI/ML, (b) provide an overview of common ML approaches used in laboratory medicine, (c) describe the current AI/ML landscape as it relates infectious disease testing, and (d) discuss the future evolution AI/ML for infectious disease testing in both laboratory and point-of-care applications. Summary The review provides an important educational overview of AI/ML technique in the context of infectious disease testing. This includes supervised ML approaches, which are frequently used in laboratory medicine applications including infectious diseases, such as COVID-19, sepsis, hepatitis, malaria, meningitis, Lyme disease, and tuberculosis. We also apply the concept of \\u201cdata fusion\\u201d describing the future of laboratory testing where multiple data streams are integrated by AI/ML to provide actionable clinical knowledge.\",\n          \"Given its advantages in low latency, fast response, context-aware services, mobility, and privacy preservation, edge computing has emerged as the key support for intelligent applications and 5G/6G Internet of things (IoT) networks. This technology extends the cloud by providing intermediate services at the edge of the network and improving the quality of service for latency-sensitive applications. Many AI-based solutions with machine learning, deep learning, and swarm intelligence have exhibited the high potential to perform intelligent cognitive sensing, intelligent network management, big data analytics, and security enhancement for edge-based smart applications. Despite its many benefits, there are still concerns about the required capabilities of intelligent edge computing to deal with the computational complexity of machine learning techniques for big IoT data analytics. Resource constraints of edge computing, distributed computing, efficient orchestration, and synchronization of resources are all factors that require attention for quality of service improvement and cost-effective development of edge-based smart applications. In this context, this paper aims to explore the confluence of AI and edge in many application domains in order to leverage the potential of the existing research around these factors and identify new perspectives. The confluence of edge computing and AI improves the quality of user experience in emergency situations, such as in the Internet of vehicles, where critical inaccuracies or delays can lead to damage and accidents. These are the same factors that most studies have used to evaluate the success of an edge-based application. In this review, we first provide an in-depth analysis of the state of the art of AI in edge-based applications with a focus on eight application areas: smart agriculture, smart environment, smart grid, smart healthcare, smart industry, smart education, smart transportation, and security and privacy. Then, we present a qualitative comparison that emphasizes the main objective of the confluence, the roles and the use of artificial intelligence at the network edge, and the key enabling technologies for edge analytics. Then, open challenges, future research directions, and perspectives are identified and discussed. Finally, some conclusions are drawn.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.918807046982341,\n        \"min\": 1897.0,\n        \"max\": 2026.0,\n        \"num_unique_values\": 42,\n        \"samples\": [\n          1995.0,\n          2017.0,\n          2026.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1194,\n        \"samples\": [\n          \"International Journal of Innovative Research in Engineering &amp; Multidisciplinary Physical Sciences\",\n          \"The Arabian journal for science and engineering\",\n          \"Processes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1836,\n        \"samples\": [\n          \"https://www.semanticscholar.org/paper/0026f1f4e06854198098e3eef5f4e3930dcdd3dc\",\n          \"https://www.semanticscholar.org/paper/0062f97c48b7879f52843ea9de42eabb558a1569\",\n          \"https://www.semanticscholar.org/paper/00694ae9742e30aa244d7d1f32dc99dbafac25d5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1813,\n        \"samples\": [\n          \"Hasan Y\\u0131ld\\u0131r\\u0131m\",\n          \"Jiun-Yu Wu, Chin-Chung Tsai\",\n          \"O. Rudenko, O. Bilokin\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(OUT_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TXQ4fO1fcXdM",
        "outputId": "93a10fca-8ecc-4675-f688-07f148954e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_43b89ec2-4238-41c0-b1a0-fc663b9206aa\", \"semantic_scholar_machine_learning_10000.csv\", 2359896)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_NR8c5XGWc"
      },
      "source": [
        "# Question 2 (15 points)\n",
        "\n",
        "Write a python program to **clean the text data** you collected in the previous question and save the clean data in a new column in the csv file. The data cleaning steps include: [Code and output is required for each part]\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the stopwords list.\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QX6bJjGWXY9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00e3411a-e43e-4763-ef62-67bdc62e6756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 1836\n",
            "Columns: ['paperId', 'title', 'abstract', 'year', 'venue', 'url', 'authors']\n",
            "\n",
            "Sample raw text (first 3):\n",
            "\n",
            "--- Sample 1 ---\n",
            "In the era of burgeoning electric vehicle (EV) popularity, understanding the patterns of EV users’ behavior is imperative. This paper examines the trends in household charging sessions’ timing, duration, and energy consumption by analyzing real-world residential charging data. By leveraging the information collected from each session, a novel framework is introduced for the efficient, real-time prediction of important charging characteristics. Utilizing historical data and user-specific features, machine learning models are trained to predict the connection duration, charging duration, chargin\n",
            "\n",
            "--- Sample 2 ---\n",
            "Background Meditation apps have surged in popularity in recent years, with an increasing number of individuals turning to these apps to cope with stress, including during the COVID-19 pandemic. Meditation apps are the most commonly used mental health apps for depression and anxiety. However, little is known about who is well suited to these apps. Objective This study aimed to develop and test a data-driven algorithm to predict which individuals are most likely to benefit from app-based meditation training. Methods Using randomized controlled trial data comparing a 4-week meditation app (Health\n",
            "\n",
            "--- Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 1 OUTPUT (Noise removed)\n",
            "==============================\n",
            "\n",
            "--- Step1 Sample 1 ---\n",
            "In the era of burgeoning electric vehicle EV popularity understanding the patterns of EV users behavior is imperative This paper examines the trends in household charging sessions timing duration and energy consumption by analyzing real world residential charging data By leveraging the information collected from each session a novel framework is introduced for the efficient real time prediction of important charging characteristics Utilizing historical data and user specific features machine learning models are trained to predict the connection duration charging duration charging demand and ti\n",
            "\n",
            "--- Step1 Sample 2 ---\n",
            "Background Meditation apps have surged in popularity in recent years with an increasing number of individuals turning to these apps to cope with stress including during the COVID 19 pandemic Meditation apps are the most commonly used mental health apps for depression and anxiety However little is known about who is well suited to these apps Objective This study aimed to develop and test a data driven algorithm to predict which individuals are most likely to benefit from app based meditation training Methods Using randomized controlled trial data comparing a 4 week meditation app Healthy Minds \n",
            "\n",
            "--- Step1 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 2 OUTPUT (Numbers removed)\n",
            "==============================\n",
            "\n",
            "--- Step2 Sample 1 ---\n",
            "In the era of burgeoning electric vehicle EV popularity understanding the patterns of EV users behavior is imperative This paper examines the trends in household charging sessions timing duration and energy consumption by analyzing real world residential charging data By leveraging the information collected from each session a novel framework is introduced for the efficient real time prediction of important charging characteristics Utilizing historical data and user specific features machine learning models are trained to predict the connection duration charging duration charging demand and ti\n",
            "\n",
            "--- Step2 Sample 2 ---\n",
            "Background Meditation apps have surged in popularity in recent years with an increasing number of individuals turning to these apps to cope with stress including during the COVID pandemic Meditation apps are the most commonly used mental health apps for depression and anxiety However little is known about who is well suited to these apps Objective This study aimed to develop and test a data driven algorithm to predict which individuals are most likely to benefit from app based meditation training Methods Using randomized controlled trial data comparing a week meditation app Healthy Minds Progr\n",
            "\n",
            "--- Step2 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 3 OUTPUT (Stopwords removed)\n",
            "==============================\n",
            "\n",
            "--- Step3 Sample 1 ---\n",
            "era burgeoning electric vehicle EV popularity understanding patterns EV users behavior imperative paper examines trends household charging sessions timing duration energy consumption analyzing real world residential charging data leveraging information collected session novel framework introduced efficient real time prediction important charging characteristics Utilizing historical data user specific features machine learning models trained predict connection duration charging duration charging demand time next session models enhance understanding EV users behavior provide practical tools opti\n",
            "\n",
            "--- Step3 Sample 2 ---\n",
            "Background Meditation apps surged popularity recent years increasing number individuals turning apps cope stress including COVID pandemic Meditation apps commonly used mental health apps depression anxiety However little known well suited apps Objective study aimed develop test data driven algorithm predict individuals likely benefit app based meditation training Methods Using randomized controlled trial data comparing week meditation app Healthy Minds Program HMP assessment control condition school system employees n developed algorithm predict likely benefit HMP Baseline clinical demographic\n",
            "\n",
            "--- Step3 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 4 OUTPUT (Lowercased)\n",
            "==============================\n",
            "\n",
            "--- Step4 Sample 1 ---\n",
            "era burgeoning electric vehicle ev popularity understanding patterns ev users behavior imperative paper examines trends household charging sessions timing duration energy consumption analyzing real world residential charging data leveraging information collected session novel framework introduced efficient real time prediction important charging characteristics utilizing historical data user specific features machine learning models trained predict connection duration charging duration charging demand time next session models enhance understanding ev users behavior provide practical tools opti\n",
            "\n",
            "--- Step4 Sample 2 ---\n",
            "background meditation apps surged popularity recent years increasing number individuals turning apps cope stress including covid pandemic meditation apps commonly used mental health apps depression anxiety however little known well suited apps objective study aimed develop test data driven algorithm predict individuals likely benefit app based meditation training methods using randomized controlled trial data comparing week meditation app healthy minds program hmp assessment control condition school system employees n developed algorithm predict likely benefit hmp baseline clinical demographic\n",
            "\n",
            "--- Step4 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 5 OUTPUT (Stemmed)\n",
            "==============================\n",
            "\n",
            "--- Step5 Sample 1 ---\n",
            "era burgeon electr vehicl ev popular understand pattern ev user behavior imper paper examin trend household charg session time durat energi consumpt analyz real world residenti charg data leverag inform collect session novel framework introduc effici real time predict import charg characterist util histor data user specif featur machin learn model train predict connect durat charg durat charg demand time next session model enhanc understand ev user behavior provid practic tool optim ev charg infrastructur effect manag charg demand transport sector becom increasingli electrifi work aim empow st\n",
            "\n",
            "--- Step5 Sample 2 ---\n",
            "background medit app surg popular recent year increas number individu turn app cope stress includ covid pandem medit app commonli use mental health app depress anxieti howev littl known well suit app object studi aim develop test data driven algorithm predict individu like benefit app base medit train method use random control trial data compar week medit app healthi mind program hmp assess control condit school system employe n develop algorithm predict like benefit hmp baselin clinic demograph characterist submit machin learn model develop person advantag index pai reflect individu expect re\n",
            "\n",
            "--- Step5 Sample 3 ---\n",
            "\n",
            "\n",
            "\n",
            "==============================\n",
            "STEP 6 OUTPUT (Lemmatized)\n",
            "==============================\n",
            "\n",
            "--- Step6 Sample 1 ---\n",
            "era burgeoning electric vehicle ev popularity understanding pattern ev user behavior imperative paper examines trend household charging session timing duration energy consumption analyzing real world residential charging data leveraging information collected session novel framework introduced efficient real time prediction important charging characteristic utilizing historical data user specific feature machine learning model trained predict connection duration charging duration charging demand time next session model enhance understanding ev user behavior provide practical tool optimizing ev \n",
            "\n",
            "--- Step6 Sample 2 ---\n",
            "background meditation apps surged popularity recent year increasing number individual turning apps cope stress including covid pandemic meditation apps commonly used mental health apps depression anxiety however little known well suited apps objective study aimed develop test data driven algorithm predict individual likely benefit app based meditation training method using randomized controlled trial data comparing week meditation app healthy mind program hmp assessment control condition school system employee n developed algorithm predict likely benefit hmp baseline clinical demographic chara\n",
            "\n",
            "--- Step6 Sample 3 ---\n",
            "\n",
            "\n",
            "✅ Saved cleaned CSV with new column 'clean_text' to: semantic_scholar_machine_learning_10000_cleaned.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            abstract  \\\n",
              "0  In the era of burgeoning electric vehicle (EV)...   \n",
              "1  Background Meditation apps have surged in popu...   \n",
              "2                                                NaN   \n",
              "3  Background Humans must be able to cope with th...   \n",
              "4  The growing number of cloud-based services has...   \n",
              "\n",
              "                                          clean_text  \n",
              "0  era burgeoning electric vehicle ev popularity ...  \n",
              "1  background meditation apps surged popularity r...  \n",
              "2                                                     \n",
              "3  background human must able cope huge amount in...  \n",
              "4  growing number cloud based service led rising ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5685548-14b7-4600-9729-0ca7ec022cfb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In the era of burgeoning electric vehicle (EV)...</td>\n",
              "      <td>era burgeoning electric vehicle ev popularity ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Background Meditation apps have surged in popu...</td>\n",
              "      <td>background meditation apps surged popularity r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Background Humans must be able to cope with th...</td>\n",
              "      <td>background human must able cope huge amount in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The growing number of cloud-based services has...</td>\n",
              "      <td>growing number cloud based service led rising ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5685548-14b7-4600-9729-0ca7ec022cfb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5685548-14b7-4600-9729-0ca7ec022cfb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5685548-14b7-4600-9729-0ca7ec022cfb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[[TEXT_COL, \\\"clean_text\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Background Meditation apps have surged in popularity in recent years, with an increasing number of individuals turning to these apps to cope with stress, including during the COVID-19 pandemic. Meditation apps are the most commonly used mental health apps for depression and anxiety. However, little is known about who is well suited to these apps. Objective This study aimed to develop and test a data-driven algorithm to predict which individuals are most likely to benefit from app-based meditation training. Methods Using randomized controlled trial data comparing a 4-week meditation app (Healthy Minds Program [HMP]) with an assessment-only control condition in school system employees (n=662), we developed an algorithm to predict who is most likely to benefit from HMP. Baseline clinical and demographic characteristics were submitted to a machine learning model to develop a \\u201cPersonalized Advantage Index\\u201d (PAI) reflecting an individual\\u2019s expected reduction in distress (primary outcome) from HMP versus control. Results A significant group \\u00d7 PAI interaction emerged (t658=3.30; P=.001), indicating that PAI scores moderated group differences in outcomes. A regression model that included repetitive negative thinking as the sole baseline predictor performed comparably well. Finally, we demonstrate the translation of a predictive model into personalized recommendations of expected benefit. Conclusions Overall, the results revealed the potential of a data-driven algorithm to inform which individuals are most likely to benefit from a meditation app. Such an algorithm could be used to objectively communicate expected benefits to individuals, allowing them to make more informed decisions about whether a meditation app is appropriate for them. Trial Registration ClinicalTrials.gov NCT04426318; https://clinicaltrials.gov/ct2/show/NCT04426318\",\n          \"The growing number of cloud-based services has led to a rising threat of Distributed Denial of Service (DDoS) attacks. These attacks can cause significant harm to businesses and organizations by overwhelming their network resources, resulting in the unavailability of critical services. The traditional defense mechanisms, such as firewalls systems, are becoming insufficient to cope with the scale and complexity of DDoS attacks. In this research, we propose a new machine learning approach based on ensemble learning to detect DDoS attacks in cloud environments. The proposed method utilizes various features extracted from network traffic to train machine learning algorithms. The proposed solution is expected to be effective in detecting DDoS attacks in real-time with high accuracy.\",\n          \"In the era of burgeoning electric vehicle (EV) popularity, understanding the patterns of EV users\\u2019 behavior is imperative. This paper examines the trends in household charging sessions\\u2019 timing, duration, and energy consumption by analyzing real-world residential charging data. By leveraging the information collected from each session, a novel framework is introduced for the efficient, real-time prediction of important charging characteristics. Utilizing historical data and user-specific features, machine learning models are trained to predict the connection duration, charging duration, charging demand, and time until the next session. These models enhance the understanding of EV users\\u2019 behavior and provide practical tools for optimizing the EV charging infrastructure and effectively managing the charging demand. As the transportation sector becomes increasingly electrified, this work aims to empower stakeholders with insights and reliable models, enabling them to anticipate the localized demand and contribute to the sustainable integration of electric vehicles into the grid.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"background meditation apps surged popularity recent year increasing number individual turning apps cope stress including covid pandemic meditation apps commonly used mental health apps depression anxiety however little known well suited apps objective study aimed develop test data driven algorithm predict individual likely benefit app based meditation training method using randomized controlled trial data comparing week meditation app healthy mind program hmp assessment control condition school system employee n developed algorithm predict likely benefit hmp baseline clinical demographic characteristic submitted machine learning model develop personalized advantage index pai reflecting individual expected reduction distress primary outcome hmp versus control result significant group pai interaction emerged p indicating pai score moderated group difference outcome regression model included repetitive negative thinking sole baseline predictor performed comparably well finally demonstrate translation predictive model personalized recommendation expected benefit conclusion overall result revealed potential data driven algorithm inform individual likely benefit meditation app algorithm could used objectively communicate expected benefit individual allowing make informed decision whether meditation app appropriate trial registration clinicaltrials gov nct http clinicaltrials gov ct show nct\",\n          \"growing number cloud based service led rising threat distributed denial service ddos attack attack cause significant harm business organization overwhelming network resource resulting unavailability critical service traditional defense mechanism firewall system becoming insufficient cope scale complexity ddos attack research propose new machine learning approach based ensemble learning detect ddos attack cloud environment proposed method utilizes various feature extracted network traffic train machine learning algorithm proposed solution expected effective detecting ddos attack real time high accuracy\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "!pip -q install pandas nltk\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "\n",
        "\n",
        "INPUT_CSV = \"semantic_scholar_machine_learning_10000.csv\"\n",
        "TEXT_COL = \"abstract\"\n",
        "\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "sample_series = df[TEXT_COL].fillna(\"\").astype(str).head(3)\n",
        "print(\"\\nSample raw text (first 3):\")\n",
        "for i, t in enumerate(sample_series, start=1):\n",
        "    print(f\"\\n--- Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "def remove_noise(text: str) -> str:\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "step1 = sample_series.apply(remove_noise)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 1 OUTPUT (Noise removed)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step1, start=1):\n",
        "    print(f\"\\n--- Step1 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "def remove_numbers(text: str) -> str:\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "step2 = step1.apply(remove_numbers)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 2 OUTPUT (Numbers removed)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step2, start=1):\n",
        "    print(f\"\\n--- Step2 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered = [w for w in tokens if w.lower() not in STOPWORDS]\n",
        "    return \" \".join(filtered)\n",
        "\n",
        "step3 = step2.apply(remove_stopwords)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 3 OUTPUT (Stopwords removed)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step3, start=1):\n",
        "    print(f\"\\n--- Step3 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "def to_lower(text: str) -> str:\n",
        "    return text.lower()\n",
        "\n",
        "step4 = step3.apply(to_lower)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 4 OUTPUT (Lowercased)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step4, start=1):\n",
        "    print(f\"\\n--- Step4 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_text(text: str) -> str:\n",
        "    tokens = word_tokenize(text)\n",
        "    stemmed = [stemmer.stem(w) for w in tokens]\n",
        "    return \" \".join(stemmed)\n",
        "\n",
        "step5 = step4.apply(stem_text)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 5 OUTPUT (Stemmed)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step5, start=1):\n",
        "    print(f\"\\n--- Step5 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text: str) -> str:\n",
        "    tokens = word_tokenize(text)\n",
        "    lemmas = [lemmatizer.lemmatize(w) for w in tokens]\n",
        "    return \" \".join(lemmas)\n",
        "\n",
        "step6 = step4.apply(lemmatize_text)\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"STEP 6 OUTPUT (Lemmatized)\")\n",
        "print(\"==============================\")\n",
        "for i, t in enumerate(step6, start=1):\n",
        "    print(f\"\\n--- Step6 Sample {i} ---\\n{t[:600]}\")\n",
        "\n",
        "\n",
        "def full_clean_pipeline(text: str) -> str:\n",
        "    if pd.isna(text):\n",
        "        text = \"\"\n",
        "    text = str(text)\n",
        "\n",
        "    text = remove_noise(text)\n",
        "    text = remove_numbers(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = to_lower(text)\n",
        "    text = lemmatize_text(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "df[\"clean_text\"] = df[TEXT_COL].apply(full_clean_pipeline)\n",
        "\n",
        "OUTPUT_CSV = INPUT_CSV.replace(\".csv\", \"_cleaned.csv\")\n",
        "df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n✅ Saved cleaned CSV with new column 'clean_text' to:\", OUTPUT_CSV)\n",
        "\n",
        "\n",
        "df[[TEXT_COL, \"clean_text\"]].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(OUTPUT_CSV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RytSbTtHeDoh",
        "outputId": "b53430d7-770e-4724-a486-ee8719acc2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1211646b-b06e-4465-b702-a4392da1ee54\", \"semantic_scholar_machine_learning_10000_cleaned.csv\", 3727943)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_PZdH9Sh49"
      },
      "source": [
        "# Question 3 (15 points)\n",
        "\n",
        "Write a python program to **conduct syntax and structure analysis of the clean text** you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) **Parts of Speech (POS) Tagging:** Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) **Constituency Parsing and Dependency Parsing:** print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) **Named Entity Recognition:** Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0oOSlsOS0cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ac5f00-22fe-4c96-e349-811f65f6c379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/12.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/12.8 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m11.4/12.8 MB\u001b[0m \u001b[31m144.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m148.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Rows: 1836\n",
            "Columns: ['paperId', 'title', 'abstract', 'year', 'venue', 'url', 'authors', 'clean_text']\n",
            "\n",
            "==============================\n",
            "EXAMPLE SENTENCE (used for parsing)\n",
            "==============================\n",
            "era burgeoning electric vehicle ev popularity understanding pattern ev user behavior imperative paper examines trend household charging session timing duration energy consumption analyzing real world residential charging data leveraging information collected session novel framework introduced efficient real time prediction important charging characteristic utilizing historical data user specific feature machine learning model trained predict connection duration charging duration charging demand time next session model enhance understanding ev user behavior provide practical tool optimizing ev charging infrastructure effectively managing charging demand transportation sector becomes increasingly electrified work aim empower stakeholder insight reliable model enabling anticipate localized demand contribute sustainable integration electric vehicle grid\n",
            "\n",
            "==============================\n",
            "PART (1) POS TAGGING COUNTS\n",
            "==============================\n",
            "Processed rows: 1000\n",
            "Total Nouns: 50005\n",
            "Total Verbs: 16380\n",
            "Total Adjectives: 21171\n",
            "Total Adverbs: 3739\n",
            "\n",
            "POS tags for example sentence:\n",
            "[('era', 'NN'), ('burgeoning', 'VBG'), ('electric', 'JJ'), ('vehicle', 'NN'), ('ev', 'NN'), ('popularity', 'NN'), ('understanding', 'VBG'), ('pattern', 'JJ'), ('ev', 'JJ'), ('user', 'NN'), ('behavior', 'NN'), ('imperative', 'JJ'), ('paper', 'NN'), ('examines', 'NNS'), ('trend', 'NN'), ('household', 'NN'), ('charging', 'VBG'), ('session', 'NN'), ('timing', 'VBG'), ('duration', 'NN'), ('energy', 'NN'), ('consumption', 'NN'), ('analyzing', 'VBG'), ('real', 'JJ'), ('world', 'NN'), ('residential', 'JJ'), ('charging', 'VBG'), ('data', 'NNS'), ('leveraging', 'VBG'), ('information', 'NN'), ('collected', 'VBN'), ('session', 'NN'), ('novel', 'NN'), ('framework', 'NN'), ('introduced', 'VBD'), ('efficient', 'JJ'), ('real', 'JJ'), ('time', 'NN'), ('prediction', 'NN'), ('important', 'JJ'), ('charging', 'VBG'), ('characteristic', 'JJ'), ('utilizing', 'JJ'), ('historical', 'JJ'), ('data', 'NNS'), ('user', 'NN'), ('specific', 'JJ'), ('feature', 'NN'), ('machine', 'NN'), ('learning', 'VBG'), ('model', 'NN'), ('trained', 'VBD'), ('predict', 'JJ'), ('connection', 'NN'), ('duration', 'NN'), ('charging', 'VBG'), ('duration', 'NN'), ('charging', 'VBG'), ('demand', 'NN'), ('time', 'NN'), ('next', 'JJ'), ('session', 'NN'), ('model', 'NN'), ('enhance', 'NN'), ('understanding', 'VBG'), ('ev', 'CC'), ('user', 'JJ'), ('behavior', 'NN'), ('provide', 'VBP'), ('practical', 'JJ'), ('tool', 'NN'), ('optimizing', 'VBG'), ('ev', 'JJ'), ('charging', 'VBG'), ('infrastructure', 'NN'), ('effectively', 'RB'), ('managing', 'VBG'), ('charging', 'VBG'), ('demand', 'NN'), ('transportation', 'NN'), ('sector', 'NN'), ('becomes', 'VBZ'), ('increasingly', 'RB'), ('electrified', 'JJ'), ('work', 'NN'), ('aim', 'NN'), ('empower', 'VB'), ('stakeholder', 'NN'), ('insight', 'NN'), ('reliable', 'JJ'), ('model', 'NN'), ('enabling', 'VBG'), ('anticipate', 'JJ'), ('localized', 'VBN'), ('demand', 'NN'), ('contribute', 'NN'), ('sustainable', 'JJ'), ('integration', 'NN'), ('electric', 'JJ'), ('vehicle', 'NN'), ('grid', 'NN')]\n",
            "\n",
            "==============================\n",
            "PART (2) CONSTITUENCY TREE (NLTK ne_chunk Tree)\n",
            "==============================\n",
            "(S\n",
            "  era/NN\n",
            "  burgeoning/VBG\n",
            "  electric/JJ\n",
            "  vehicle/NN\n",
            "  ev/NN\n",
            "  popularity/NN\n",
            "  understanding/VBG\n",
            "  pattern/JJ\n",
            "  ev/JJ\n",
            "  user/NN\n",
            "  behavior/NN\n",
            "  imperative/JJ\n",
            "  paper/NN\n",
            "  examines/NNS\n",
            "  trend/NN\n",
            "  household/NN\n",
            "  charging/VBG\n",
            "  session/NN\n",
            "  timing/VBG\n",
            "  duration/NN\n",
            "  energy/NN\n",
            "  consumption/NN\n",
            "  analyzing/VBG\n",
            "  real/JJ\n",
            "  world/NN\n",
            "  residential/JJ\n",
            "  charging/VBG\n",
            "  data/NNS\n",
            "  leveraging/VBG\n",
            "  information/NN\n",
            "  collected/VBN\n",
            "  session/NN\n",
            "  novel/NN\n",
            "  framework/NN\n",
            "  introduced/VBD\n",
            "  efficient/JJ\n",
            "  real/JJ\n",
            "  time/NN\n",
            "  prediction/NN\n",
            "  important/JJ\n",
            "  charging/VBG\n",
            "  characteristic/JJ\n",
            "  utilizing/JJ\n",
            "  historical/JJ\n",
            "  data/NNS\n",
            "  user/NN\n",
            "  specific/JJ\n",
            "  feature/NN\n",
            "  machine/NN\n",
            "  learning/VBG\n",
            "  model/NN\n",
            "  trained/VBD\n",
            "  predict/JJ\n",
            "  connection/NN\n",
            "  duration/NN\n",
            "  charging/VBG\n",
            "  duration/NN\n",
            "  charging/VBG\n",
            "  demand/NN\n",
            "  time/NN\n",
            "  next/JJ\n",
            "  session/NN\n",
            "  model/NN\n",
            "  enhance/NN\n",
            "  understanding/VBG\n",
            "  ev/CC\n",
            "  user/JJ\n",
            "  behavior/NN\n",
            "  provide/VBP\n",
            "  practical/JJ\n",
            "  tool/NN\n",
            "  optimizing/VBG\n",
            "  ev/JJ\n",
            "  charging/VBG\n",
            "  infrastructure/NN\n",
            "  effectively/RB\n",
            "  managing/VBG\n",
            "  charging/VBG\n",
            "  demand/NN\n",
            "  transportation/NN\n",
            "  sector/NN\n",
            "  becomes/VBZ\n",
            "  increasingly/RB\n",
            "  electrified/JJ\n",
            "  work/NN\n",
            "  aim/NN\n",
            "  empower/VB\n",
            "  stakeholder/NN\n",
            "  insight/NN\n",
            "  reliable/JJ\n",
            "  model/NN\n",
            "  enabling/VBG\n",
            "  anticipate/JJ\n",
            "  localized/VBN\n",
            "  demand/NN\n",
            "  contribute/NN\n",
            "  sustainable/JJ\n",
            "  integration/NN\n",
            "  electric/JJ\n",
            "  vehicle/NN\n",
            "  grid/NN)\n",
            "\n",
            "==============================\n",
            "PART (2) DEPENDENCY PARSE (spaCy)\n",
            "==============================\n",
            "era             --> vehicle         (nmod)\n",
            "burgeoning      --> vehicle         (amod)\n",
            "electric        --> vehicle         (amod)\n",
            "vehicle         --> collected       (nsubj)\n",
            "ev              --> vehicle         (prep)\n",
            "popularity      --> understanding   (compound)\n",
            "understanding   --> pattern         (compound)\n",
            "pattern         --> ev              (pobj)\n",
            "ev              --> vehicle         (prep)\n",
            "user            --> behavior        (compound)\n",
            "behavior        --> ev              (pobj)\n",
            "imperative      --> paper           (amod)\n",
            "paper           --> examines        (compound)\n",
            "examines        --> session         (compound)\n",
            "trend           --> session         (compound)\n",
            "household       --> charging        (compound)\n",
            "charging        --> session         (compound)\n",
            "session         --> vehicle         (appos)\n",
            "timing          --> session         (acl)\n",
            "duration        --> consumption     (compound)\n",
            "energy          --> consumption     (compound)\n",
            "consumption     --> timing          (dobj)\n",
            "analyzing       --> session         (acl)\n",
            "real            --> world           (amod)\n",
            "world           --> residential     (compound)\n",
            "residential     --> analyzing       (dobj)\n",
            "charging        --> session         (acl)\n",
            "data            --> charging        (dobj)\n",
            "leveraging      --> data            (acl)\n",
            "information     --> collected       (npadvmod)\n",
            "collected       --> framework       (amod)\n",
            "session         --> novel           (compound)\n",
            "novel           --> framework       (amod)\n",
            "framework       --> introduced      (nsubj)\n",
            "introduced      --> introduced      (ROOT)\n",
            "efficient       --> prediction      (amod)\n",
            "real            --> time            (amod)\n",
            "time            --> prediction      (compound)\n",
            "prediction      --> introduced      (dobj)\n",
            "important       --> prediction      (amod)\n",
            "charging        --> introduced      (advcl)\n",
            "characteristic  --> utilizing       (amod)\n",
            "utilizing       --> model           (amod)\n",
            "historical      --> machine         (amod)\n",
            "data            --> user            (compound)\n",
            "user            --> machine         (nmod)\n",
            "specific        --> machine         (amod)\n",
            "feature         --> machine         (compound)\n",
            "machine         --> model           (compound)\n",
            "learning        --> model           (compound)\n",
            "model           --> charging        (dobj)\n",
            "trained         --> duration        (amod)\n",
            "predict         --> duration        (amod)\n",
            "connection      --> duration        (compound)\n",
            "duration        --> model           (appos)\n",
            "charging        --> duration        (acl)\n",
            "duration        --> charging        (compound)\n",
            "charging        --> time            (amod)\n",
            "demand          --> time            (compound)\n",
            "time            --> charging        (dobj)\n",
            "next            --> enhance         (amod)\n",
            "session         --> model           (compound)\n",
            "model           --> enhance         (compound)\n",
            "enhance         --> understanding   (compound)\n",
            "understanding   --> provide         (nsubj)\n",
            "ev              --> understanding   (prep)\n",
            "user            --> behavior        (compound)\n",
            "behavior        --> ev              (pobj)\n",
            "provide         --> introduced      (advcl)\n",
            "practical       --> tool            (amod)\n",
            "tool            --> provide         (dobj)\n",
            "optimizing      --> tool            (acl)\n",
            "ev              --> optimizing      (prep)\n",
            "charging        --> ev              (pcomp)\n",
            "infrastructure  --> charging        (dobj)\n",
            "effectively     --> managing        (advmod)\n",
            "managing        --> ev              (pcomp)\n",
            "charging        --> sector          (amod)\n",
            "demand          --> sector          (compound)\n",
            "transportation  --> sector          (compound)\n",
            "sector          --> managing        (dobj)\n",
            "becomes         --> introduced      (conj)\n",
            "increasingly    --> electrified     (advmod)\n",
            "electrified     --> aim             (amod)\n",
            "work            --> aim             (compound)\n",
            "aim             --> empower         (compound)\n",
            "empower         --> becomes         (acomp)\n",
            "stakeholder     --> insight         (compound)\n",
            "insight         --> empower         (dobj)\n",
            "reliable        --> model           (amod)\n",
            "model           --> introduced      (dobj)\n",
            "enabling        --> demand          (amod)\n",
            "anticipate      --> demand          (nmod)\n",
            "localized       --> demand          (amod)\n",
            "demand          --> contribute      (nsubj)\n",
            "contribute      --> contribute      (ROOT)\n",
            "sustainable     --> grid            (amod)\n",
            "integration     --> vehicle         (nmod)\n",
            "electric        --> vehicle         (compound)\n",
            "vehicle         --> grid            (compound)\n",
            "grid            --> contribute      (dobj)\n",
            "\n",
            "==============================\n",
            "EXPLANATION (One sentence)\n",
            "==============================\n",
            "Constituency tree groups words into nested phrase units (hierarchical structure).\n",
            "Dependency tree links each word to a head word and labels the grammatical relation (subject, object, modifier).\n",
            "\n",
            "==============================\n",
            "PART (3) NER ENTITY COUNTS (by type)\n",
            "==============================\n",
            "Processed rows: 1000\n",
            "CARDINAL  : 528\n",
            "ORG       : 515\n",
            "PERSON    : 436\n",
            "DATE      : 195\n",
            "GPE       : 182\n",
            "ORDINAL   : 164\n",
            "NORP      : 128\n",
            "TIME      : 21\n",
            "LOC       : 15\n",
            "PRODUCT   : 13\n",
            "LANGUAGE  : 12\n",
            "QUANTITY  : 8\n",
            "FAC       : 4\n",
            "PERCENT   : 2\n",
            "WORK_OF_ART: 1\n",
            "\n",
            "Top 20 entity strings:\n",
            "two                            153\n",
            "three                          110\n",
            "one                            88\n",
            "first                          78\n",
            "cnn                            61\n",
            "second                         44\n",
            "four                           36\n",
            "five                           34\n",
            "english                        26\n",
            "recent year                    23\n",
            "six                            20\n",
            "machine svm                    17\n",
            "china                          16\n",
            "daily                          16\n",
            "vector                         15\n",
            "third                          14\n",
            "eight                          14\n",
            "arabic                         14\n",
            "firstly                        13\n",
            "today                          12\n",
            "\n",
            "✅ Saved NER counts file: ner_entity_type_counts.csv\n"
          ]
        }
      ],
      "source": [
        "!pip -q install pandas spacy nltk\n",
        "\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download(\"maxent_ne_chunker_tab\")\n",
        "nltk.download(\"words\")\n",
        "\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.chunk import ne_chunk\n",
        "\n",
        "\n",
        "import spacy\n",
        "!python -m spacy download en_core_web_sm -q\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "CLEAN_CSV = \"semantic_scholar_machine_learning_10000_cleaned.csv\"\n",
        "TEXT_COL = \"clean_text\"\n",
        "\n",
        "df = pd.read_csv(CLEAN_CSV)\n",
        "df[TEXT_COL] = df[TEXT_COL].fillna(\"\").astype(str)\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "example_sentence = None\n",
        "for text in df[TEXT_COL].head(200):\n",
        "    if text.strip():\n",
        "        sents = sent_tokenize(text)\n",
        "        if sents:\n",
        "            example_sentence = sents[0]\n",
        "            break\n",
        "\n",
        "if not example_sentence:\n",
        "    raise ValueError(\"No valid clean_text sentence found. Check your CSV.\")\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"EXAMPLE SENTENCE (used for parsing)\")\n",
        "print(\"==============================\")\n",
        "print(example_sentence)\n",
        "\n",
        "\n",
        "N_ROWS = 1000\n",
        "texts_for_pos = df[TEXT_COL].head(N_ROWS).tolist()\n",
        "\n",
        "noun_tags = {\"NN\", \"NNS\", \"NNP\", \"NNPS\"}\n",
        "verb_tags = {\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"}\n",
        "adj_tags  = {\"JJ\", \"JJR\", \"JJS\"}\n",
        "adv_tags  = {\"RB\", \"RBR\", \"RBS\"}\n",
        "\n",
        "noun_count = verb_count = adj_count = adv_count = 0\n",
        "\n",
        "for txt in texts_for_pos:\n",
        "    tokens = word_tokenize(txt)\n",
        "    tags = pos_tag(tokens)\n",
        "    for _, t in tags:\n",
        "        if t in noun_tags:\n",
        "            noun_count += 1\n",
        "        elif t in verb_tags:\n",
        "            verb_count += 1\n",
        "        elif t in adj_tags:\n",
        "            adj_count += 1\n",
        "        elif t in adv_tags:\n",
        "            adv_count += 1\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"PART (1) POS TAGGING COUNTS\")\n",
        "print(\"==============================\")\n",
        "print(\"Processed rows:\", N_ROWS)\n",
        "print(\"Total Nouns:\", noun_count)\n",
        "print(\"Total Verbs:\", verb_count)\n",
        "print(\"Total Adjectives:\", adj_count)\n",
        "print(\"Total Adverbs:\", adv_count)\n",
        "\n",
        "print(\"\\nPOS tags for example sentence:\")\n",
        "ex_tokens = word_tokenize(example_sentence)\n",
        "ex_pos = pos_tag(ex_tokens)\n",
        "print(ex_pos)\n",
        "\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"PART (2) CONSTITUENCY TREE (NLTK ne_chunk Tree)\")\n",
        "print(\"==============================\")\n",
        "chunk_tree = ne_chunk(ex_pos)\n",
        "print(chunk_tree)\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"PART (2) DEPENDENCY PARSE (spaCy)\")\n",
        "print(\"==============================\")\n",
        "doc_sent = nlp(example_sentence)\n",
        "for token in doc_sent:\n",
        "    if token.is_space:\n",
        "        continue\n",
        "    print(f\"{token.text:<15} --> {token.head.text:<15} ({token.dep_})\")\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"EXPLANATION (One sentence)\")\n",
        "print(\"==============================\")\n",
        "print(\"Constituency tree groups words into nested phrase units (hierarchical structure).\")\n",
        "print(\"Dependency tree links each word to a head word and labels the grammatical relation (subject, object, modifier).\")\n",
        "\n",
        "\n",
        "N_ROWS_NER = 1000\n",
        "texts_for_ner = df[TEXT_COL].head(N_ROWS_NER).tolist()\n",
        "\n",
        "entity_type_counts = Counter()\n",
        "entity_text_counts = Counter()\n",
        "\n",
        "for doc in nlp.pipe(texts_for_ner, batch_size=30):\n",
        "    for ent in doc.ents:\n",
        "        entity_type_counts[ent.label_] += 1\n",
        "        entity_text_counts[ent.text] += 1\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"PART (3) NER ENTITY COUNTS (by type)\")\n",
        "print(\"==============================\")\n",
        "print(\"Processed rows:\", N_ROWS_NER)\n",
        "for label, cnt in entity_type_counts.most_common():\n",
        "    print(f\"{label:<10}: {cnt}\")\n",
        "\n",
        "print(\"\\nTop 20 entity strings:\")\n",
        "for ent, cnt in entity_text_counts.most_common(20):\n",
        "    print(f\"{ent:<30} {cnt}\")\n",
        "\n",
        "\n",
        "ner_df = pd.DataFrame(entity_type_counts.items(), columns=[\"entity_type\", \"count\"]).sort_values(\"count\", ascending=False)\n",
        "ner_df.to_csv(\"ner_entity_type_counts.csv\", index=False)\n",
        "\n",
        "print(\"\\n✅ Saved NER counts file: ner_entity_type_counts.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"ner_entity_type_counts.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "2-HhoR5Ygx5p",
        "outputId": "4c9f5ffd-6eeb-4e6d-e198-378c1827937c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c6ce552b-af19-4046-ac89-ac3bc3e56f19\", \"ner_entity_type_counts.csv\", 167)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Following Questions must answer using AI assitance**"
      ],
      "metadata": {
        "id": "EcVqy1yj3wja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 4 (20 points)."
      ],
      "metadata": {
        "id": "kEdcyHX8VaDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. (PART-1)\n",
        "Web scraping data from the GitHub Marketplace to gather details about popular actions. Using Python, the process begins by sending HTTP requests to multiple pages of the marketplace (1000 products), handling pagination through dynamic page numbers. The key details extracted include the product name, a short description, and the URL.\n",
        "\n",
        " The extracted data is stored in a structured CSV format with columns for product name, description, URL, and page number. A time delay is introduced between requests to avoid server overload. ChatGPT can assist by helping with the parsing of HTML, error handling, and generating reports based on the data collected.\n",
        "\n",
        " The goal is to complete the scraping within a specified time limit, ensuring that the process is efficient and adheres to GitHub’s usage guidelines.\n",
        "\n",
        "(PART -2)\n",
        "\n",
        "1.   **Preprocess Data**: Clean the text by tokenizing, removing stopwords, and converting to lowercase.\n",
        "\n",
        "2. Perform **Data Quality** operations.\n",
        "\n",
        "\n",
        "Preprocessing:\n",
        "Preprocessing involves cleaning the text by removing noise such as special characters, HTML tags, and unnecessary whitespace. It also includes tasks like tokenization, stopword removal, and lemmatization to standardize the text for analysis.\n",
        "\n",
        "Data Quality:\n",
        "Data quality checks ensure completeness, consistency, and accuracy by verifying that all required columns are filled and formatted correctly. Additionally, it involves identifying and removing duplicates, handling missing values, and ensuring the data reflects the true content accurately.\n"
      ],
      "metadata": {
        "id": "1Ung5_YW3C6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part - 1"
      ],
      "metadata": {
        "id": "4vy2iJtF6prX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github MarketPlace page:\n",
        "https://github.com/marketplace?type=actions"
      ],
      "metadata": {
        "id": "CTOfUpatronW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install requests beautifulsoup4 pandas tqdm\n",
        "\n",
        "import time, re, requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm.auto import tqdm\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "BASE = \"https://github.com\"\n",
        "MARKET_URL = \"https://github.com/marketplace\"\n",
        "\n",
        "TYPE = \"actions\"\n",
        "SORT = \"popularity\"\n",
        "TARGET_N = 1000\n",
        "SLEEP_SECONDS = 1.2\n",
        "MAX_PAGES = 600\n",
        "\n",
        "OUT_CSV = \"github_marketplace_actions_1000.csv\"\n",
        "\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36\",\n",
        "    \"Accept-Language\": \"en-US,en;q=0.9\"\n",
        "}\n",
        "\n",
        "def clean_ws(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", (s or \"\")).strip()\n",
        "\n",
        "def fetch_page(page_num: int, max_retries: int = 6):\n",
        "    params = {\"type\": TYPE, \"sort\": SORT, \"page\": page_num}\n",
        "    backoff = 1.0\n",
        "    for _ in range(max_retries):\n",
        "        try:\n",
        "            r = requests.get(MARKET_URL, params=params, headers=HEADERS, timeout=30)\n",
        "            if r.status_code == 200:\n",
        "                return r.text\n",
        "            if r.status_code in (429, 500, 502, 503, 504):\n",
        "                time.sleep(backoff)\n",
        "                backoff = min(backoff * 2, 30)\n",
        "                continue\n",
        "            print(f\"HTTP {r.status_code} on page {page_num}\")\n",
        "            return None\n",
        "        except requests.RequestException:\n",
        "            time.sleep(backoff)\n",
        "            backoff = min(backoff * 2, 30)\n",
        "    return None\n",
        "\n",
        "def parse_actions(html: str, page_num: int):\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    rows = []\n",
        "    seen = set()\n",
        "\n",
        "\n",
        "    anchors = soup.select('a[href^=\"/marketplace/actions/\"]')\n",
        "\n",
        "    for a in anchors:\n",
        "        href = (a.get(\"href\") or \"\").strip()\n",
        "        name = clean_ws(a.get_text(\" \", strip=True))\n",
        "        if not href or not name:\n",
        "            continue\n",
        "\n",
        "        key = (href, name.lower())\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "\n",
        "        full_url = urljoin(BASE, href)\n",
        "\n",
        "\n",
        "        desc = \"\"\n",
        "        container = a.find_parent([\"li\", \"article\", \"div\", \"section\"])\n",
        "        if container:\n",
        "            p = container.find(\"p\")\n",
        "            if p:\n",
        "                desc = clean_ws(p.get_text(\" \", strip=True))\n",
        "\n",
        "        rows.append({\n",
        "            \"product_name\": name,\n",
        "            \"description\": desc,\n",
        "            \"url\": full_url,\n",
        "            \"page_number\": page_num\n",
        "        })\n",
        "\n",
        "\n",
        "    uniq = {}\n",
        "    for r in rows:\n",
        "        uniq[r[\"url\"]] = r\n",
        "    return list(uniq.values())\n",
        "\n",
        "all_rows = []\n",
        "seen_urls = set()\n",
        "\n",
        "pbar = tqdm(total=TARGET_N, desc=\"Scraping actions\", unit=\"action\")\n",
        "\n",
        "for page in range(1, MAX_PAGES + 1):\n",
        "    if len(seen_urls) >= TARGET_N:\n",
        "        break\n",
        "\n",
        "    html = fetch_page(page)\n",
        "    if not html:\n",
        "        time.sleep(SLEEP_SECONDS)\n",
        "        continue\n",
        "\n",
        "    page_rows = parse_actions(html, page)\n",
        "\n",
        "    for row in page_rows:\n",
        "        if len(seen_urls) >= TARGET_N:\n",
        "            break\n",
        "        if row[\"url\"] in seen_urls:\n",
        "            continue\n",
        "        seen_urls.add(row[\"url\"])\n",
        "        all_rows.append(row)\n",
        "        pbar.update(1)\n",
        "\n",
        "    time.sleep(SLEEP_SECONDS)\n",
        "\n",
        "pbar.close()\n",
        "\n",
        "df_actions = pd.DataFrame(all_rows)\n",
        "df_actions.to_csv(OUT_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n✅ PART-1 COMPLETE\")\n",
        "print(\"Total actions collected:\", len(df_actions))\n",
        "print(\"Saved CSV:\", OUT_CSV)\n",
        "\n",
        "df_actions.head(10)"
      ],
      "metadata": {
        "id": "4dtco9K--ks6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464,
          "referenced_widgets": [
            "88f7ece4871b493fb5b2da136ec8e970",
            "47392a21d18c4d77884c2ec8f9313bc9",
            "9407c5d9cdf14caa9c2179d8f1aa6cf0",
            "52a24b312bb849888fd9d89bf5f803a3",
            "a87b1969962346218847fc0a5b8733e4",
            "fdbcf034a6c940fa8de3ed2e69395b16",
            "c7b74f3a2c3c41e9b0283b59a087a931",
            "ac2c914905aa40beb0bd2f67fb6b39d7",
            "0d9faf36779b4878a455e4118bb2b320",
            "16cb7d5c4c4e41d996dcaeb80e40cc32",
            "84b566da6ec3493185537a9165d0ba9d"
          ]
        },
        "outputId": "3d418815-9efe-4a98-e564-f6628148c52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Scraping actions:   0%|          | 0/1000 [00:00<?, ?action/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88f7ece4871b493fb5b2da136ec8e970"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ PART-1 COMPLETE\n",
            "Total actions collected: 1000\n",
            "Saved CSV: github_marketplace_actions_1000.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             product_name description  \\\n",
              "0                          TruffleHog OSS               \n",
              "1                           Metrics embed               \n",
              "2            yq - portable yaml processor               \n",
              "3                            Super-Linter               \n",
              "4              Rebuild Armbian and Kernel               \n",
              "5                  Gosec Security Checker               \n",
              "6                                Checkout               \n",
              "7  OpenCommit — improve commits with AI 🧙               \n",
              "8                     SSH Remote Commands               \n",
              "9             Claude Code Action Official               \n",
              "\n",
              "                                                 url  page_number  \n",
              "0  https://github.com/marketplace/actions/truffle...            1  \n",
              "1  https://github.com/marketplace/actions/metrics...            1  \n",
              "2  https://github.com/marketplace/actions/yq-port...            1  \n",
              "3  https://github.com/marketplace/actions/super-l...            1  \n",
              "4  https://github.com/marketplace/actions/rebuild...            1  \n",
              "5  https://github.com/marketplace/actions/gosec-s...            1  \n",
              "6    https://github.com/marketplace/actions/checkout            1  \n",
              "7  https://github.com/marketplace/actions/opencom...            1  \n",
              "8  https://github.com/marketplace/actions/ssh-rem...            1  \n",
              "9  https://github.com/marketplace/actions/claude-...            1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2518ddbc-5025-4c00-94ba-3d9f124dfe2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "      <th>page_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TruffleHog OSS</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/truffle...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Metrics embed</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/metrics...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yq - portable yaml processor</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/yq-port...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super-Linter</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/super-l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rebuild Armbian and Kernel</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/rebuild...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Gosec Security Checker</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/gosec-s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Checkout</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/checkout</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>OpenCommit — improve commits with AI 🧙</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/opencom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SSH Remote Commands</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/ssh-rem...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Claude Code Action Official</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/claude-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2518ddbc-5025-4c00-94ba-3d9f124dfe2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2518ddbc-5025-4c00-94ba-3d9f124dfe2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2518ddbc-5025-4c00-94ba-3d9f124dfe2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_actions",
              "summary": "{\n  \"name\": \"df_actions\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"product_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"OSKAR-PHP-CS-Fixer\",\n          \"golang-govulncheck-action\",\n          \"Frogo-Keyboard-Open-Source\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"https://github.com/marketplace/actions/oskar-php-cs-fixer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 51,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2"
      ],
      "metadata": {
        "id": "gb3YwR9e7Bli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pandas nltk beautifulsoup4\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "INPUT_CSV = \"github_marketplace_actions_1000.csv\"\n",
        "CLEAN_CSV = \"github_marketplace_actions_1000_cleaned.csv\"\n",
        "QUALITY_CSV = \"github_marketplace_actions_quality_report.csv\"\n",
        "\n",
        "df = pd.read_csv(INPUT_CSV).fillna(\"\")\n",
        "\n",
        "print(\"Rows:\", len(df))\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "STOPWORDS = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def remove_html(text: str) -> str:\n",
        "    return BeautifulSoup(text, \"html.parser\").get_text(\" \")\n",
        "\n",
        "def remove_noise(text: str) -> str:\n",
        "    text = remove_html(str(text))\n",
        "    text = re.sub(r\"[^A-Za-z0-9\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text: str):\n",
        "    \"\"\"\n",
        "    Clean noise -> lowercase -> tokenize -> remove stopwords -> lemmatize\n",
        "    Returns tokens list.\n",
        "    \"\"\"\n",
        "    text = remove_noise(text).lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [t for t in tokens if t not in STOPWORDS]\n",
        "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "df[\"product_name_tokens\"] = df[\"product_name\"].apply(preprocess_text)\n",
        "df[\"description_tokens\"]  = df[\"description\"].apply(preprocess_text)\n",
        "\n",
        "df[\"product_name_clean\"] = df[\"product_name_tokens\"].apply(lambda x: \" \".join(x))\n",
        "df[\"description_clean\"]  = df[\"description_tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "print(\"\\nPreview after preprocessing:\")\n",
        "df[[\"product_name\", \"product_name_clean\", \"description\", \"description_clean\"]].head(5)\n",
        "\n",
        "quality = {}\n",
        "\n",
        "\n",
        "quality[\"missing_product_name\"] = int((df[\"product_name\"].str.strip() == \"\").sum())\n",
        "quality[\"missing_description\"]  = int((df[\"description\"].str.strip() == \"\").sum())\n",
        "quality[\"missing_url\"]          = int((df[\"url\"].str.strip() == \"\").sum())\n",
        "quality[\"missing_page_number\"]  = int(df[\"page_number\"].isna().sum())\n",
        "\n",
        "\n",
        "quality[\"duplicate_urls\"]  = int(df.duplicated(subset=[\"url\"]).sum())\n",
        "quality[\"duplicate_names\"] = int(df.duplicated(subset=[\"product_name\"]).sum())\n",
        "\n",
        "\n",
        "quality[\"invalid_url_format\"] = int((~df[\"url\"].astype(str).str.startswith(\"https://github.com/marketplace/actions/\")).sum())\n",
        "\n",
        "\n",
        "quality[\"very_short_names(<3chars)\"] = int((df[\"product_name\"].astype(str).str.len() < 3).sum())\n",
        "quality[\"very_short_desc(<10chars)\"] = int((df[\"description\"].astype(str).str.len() < 10).sum())\n",
        "\n",
        "quality_df = pd.DataFrame(list(quality.items()), columns=[\"check\", \"count\"]).sort_values(\"count\", ascending=False)\n",
        "quality_df.to_csv(QUALITY_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n✅ Data Quality Report:\")\n",
        "display(quality_df)\n",
        "\n",
        "\n",
        "df = df.drop_duplicates(subset=[\"url\"]).reset_index(drop=True)\n",
        "\n",
        "\n",
        "df.to_csv(CLEAN_CSV, index=False, encoding=\"utf-8\")\n",
        "\n",
        "print(\"\\n✅ PART-2 COMPLETE\")\n",
        "print(\"Saved cleaned CSV:\", CLEAN_CSV)\n",
        "print(\"Saved quality report CSV:\", QUALITY_CSV)\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "SPWJT78EkE__",
        "outputId": "ae744d28-0fa1-4739-97c0-036e248e5a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows: 1000\n",
            "Columns: ['product_name', 'description', 'url', 'page_number']\n",
            "\n",
            "Preview after preprocessing:\n",
            "\n",
            "✅ Data Quality Report:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                       check  count\n",
              "1        missing_description   1000\n",
              "8  very_short_desc(<10chars)   1000\n",
              "0       missing_product_name      0\n",
              "3        missing_page_number      0\n",
              "2                missing_url      0\n",
              "4             duplicate_urls      0\n",
              "5            duplicate_names      0\n",
              "6         invalid_url_format      0\n",
              "7  very_short_names(<3chars)      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ed0e5fb-cd4c-4fe2-9227-8f94a1a8d1c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>check</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>missing_description</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>very_short_desc(&lt;10chars)</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>missing_product_name</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>missing_page_number</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>missing_url</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>duplicate_urls</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>duplicate_names</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>invalid_url_format</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>very_short_names(&lt;3chars)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ed0e5fb-cd4c-4fe2-9227-8f94a1a8d1c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ed0e5fb-cd4c-4fe2-9227-8f94a1a8d1c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ed0e5fb-cd4c-4fe2-9227-8f94a1a8d1c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_2d9f4a97-9c4f-435d-a9e4-f8fd346c0efc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('quality_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2d9f4a97-9c4f-435d-a9e4-f8fd346c0efc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('quality_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "quality_df",
              "summary": "{\n  \"name\": \"quality_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"check\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"invalid_url_format\",\n          \"very_short_desc(<10chars)\",\n          \"duplicate_urls\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 440,\n        \"min\": 0,\n        \"max\": 1000,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ PART-2 COMPLETE\n",
            "Saved cleaned CSV: github_marketplace_actions_1000_cleaned.csv\n",
            "Saved quality report CSV: github_marketplace_actions_quality_report.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   product_name description  \\\n",
              "0                TruffleHog OSS               \n",
              "1                 Metrics embed               \n",
              "2  yq - portable yaml processor               \n",
              "3                  Super-Linter               \n",
              "4    Rebuild Armbian and Kernel               \n",
              "\n",
              "                                                 url  page_number  \\\n",
              "0  https://github.com/marketplace/actions/truffle...            1   \n",
              "1  https://github.com/marketplace/actions/metrics...            1   \n",
              "2  https://github.com/marketplace/actions/yq-port...            1   \n",
              "3  https://github.com/marketplace/actions/super-l...            1   \n",
              "4  https://github.com/marketplace/actions/rebuild...            1   \n",
              "\n",
              "               product_name_tokens description_tokens  \\\n",
              "0                 [trufflehog, os]                 []   \n",
              "1                  [metric, embed]                 []   \n",
              "2  [yq, portable, yaml, processor]                 []   \n",
              "3                  [super, linter]                 []   \n",
              "4       [rebuild, armbian, kernel]                 []   \n",
              "\n",
              "           product_name_clean description_clean  \n",
              "0               trufflehog os                    \n",
              "1                metric embed                    \n",
              "2  yq portable yaml processor                    \n",
              "3                super linter                    \n",
              "4      rebuild armbian kernel                    "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-989c2029-4a0d-4577-82d4-bfb32506c727\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>description</th>\n",
              "      <th>url</th>\n",
              "      <th>page_number</th>\n",
              "      <th>product_name_tokens</th>\n",
              "      <th>description_tokens</th>\n",
              "      <th>product_name_clean</th>\n",
              "      <th>description_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TruffleHog OSS</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/truffle...</td>\n",
              "      <td>1</td>\n",
              "      <td>[trufflehog, os]</td>\n",
              "      <td>[]</td>\n",
              "      <td>trufflehog os</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Metrics embed</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/metrics...</td>\n",
              "      <td>1</td>\n",
              "      <td>[metric, embed]</td>\n",
              "      <td>[]</td>\n",
              "      <td>metric embed</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yq - portable yaml processor</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/yq-port...</td>\n",
              "      <td>1</td>\n",
              "      <td>[yq, portable, yaml, processor]</td>\n",
              "      <td>[]</td>\n",
              "      <td>yq portable yaml processor</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Super-Linter</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/super-l...</td>\n",
              "      <td>1</td>\n",
              "      <td>[super, linter]</td>\n",
              "      <td>[]</td>\n",
              "      <td>super linter</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rebuild Armbian and Kernel</td>\n",
              "      <td></td>\n",
              "      <td>https://github.com/marketplace/actions/rebuild...</td>\n",
              "      <td>1</td>\n",
              "      <td>[rebuild, armbian, kernel]</td>\n",
              "      <td>[]</td>\n",
              "      <td>rebuild armbian kernel</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-989c2029-4a0d-4577-82d4-bfb32506c727')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-989c2029-4a0d-4577-82d4-bfb32506c727 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-989c2029-4a0d-4577-82d4-bfb32506c727');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"product_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"OSKAR-PHP-CS-Fixer\",\n          \"Docker Scout\",\n          \"docker-image-size-limit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"https://github.com/marketplace/actions/oskar-php-cs-fixer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 1,\n        \"max\": 51,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_name_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"product_name_clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 997,\n        \"samples\": [\n          \"set ocaml\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description_clean\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 5 (20 points)\n",
        "\n",
        "PART 1:\n",
        "Web Scrape  tweets from Twitter using the Tweepy API, specifically targeting hashtags related to subtopics (machine learning or artificial intelligence.)\n",
        "The extracted data includes the tweet ID, username, and text.\n",
        "\n",
        "Part 2:\n",
        "Perform data cleaning procedures\n",
        "\n",
        "A final data quality check ensures the completeness and consistency of the dataset. The cleaned data is then saved into a CSV file for further analysis.\n",
        "\n",
        "\n",
        "**Note**\n",
        "\n",
        "1.   Follow tutorials provided in canvas to obtain api keys. Use ChatGPT to get the code. Make sure the file is downloaded and saved.\n",
        "2.   Make sure you divide GPT code as shown in tutorials, dont make multiple requestes.\n"
      ],
      "metadata": {
        "id": "3WeD70ty3Gui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tweepy pandas"
      ],
      "metadata": {
        "id": "qYRO5Cn8bYwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tweepy\n",
        "\n",
        "\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAAHDe7wEAAAAAjKVdVFGx9ZBqxkwaycpPD4x1dwA%3DCN0ThsdVKZtP52ILRnkASDBcEdCijJr5Ro5pB4o5RkibGtTrCC\"\n",
        "\n",
        "client = tweepy.Client(bearer_token=BEARER_TOKEN, wait_on_rate_limit=True)"
      ],
      "metadata": {
        "id": "s-sqW9Tn1oeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"(#machinelearning OR #artificialintelligence) -is:retweet lang:en\"\n",
        "\n",
        "rows = []\n",
        "next_token = None\n",
        "\n",
        "\n",
        "TOTAL_TO_COLLECT = 300\n",
        "MAX_PER_REQUEST = 100\n",
        "\n",
        "while len(rows) < TOTAL_TO_COLLECT:\n",
        "    resp = client.search_recent_tweets(\n",
        "        query=query,\n",
        "        max_results=min(MAX_PER_REQUEST, TOTAL_TO_COLLECT - len(rows)),\n",
        "        tweet_fields=[\"id\", \"text\", \"author_id\", \"created_at\"],\n",
        "        expansions=[\"author_id\"],\n",
        "        user_fields=[\"username\"],\n",
        "        next_token=next_token\n",
        "    )\n",
        "\n",
        "\n",
        "    if resp.data is None:\n",
        "        break\n",
        "\n",
        "\n",
        "    user_map = {}\n",
        "    if resp.includes and \"users\" in resp.includes:\n",
        "        user_map = {u.id: u.username for u in resp.includes[\"users\"]}\n",
        "\n",
        "\n",
        "    for t in resp.data:\n",
        "        rows.append({\n",
        "            \"tweet_id\": t.id,\n",
        "            \"username\": user_map.get(t.author_id, None),\n",
        "            \"text\": t.text\n",
        "        })\n",
        "\n",
        "\n",
        "    next_token = resp.meta.get(\"next_token\")\n",
        "    if not next_token:\n",
        "        break\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print(\"Collected:\", len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "ARVTXSGn1wcr",
        "outputId": "6707e48c-2d19-4fa0-ef37-169aa00e8241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected: 300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_id        username  \\\n",
              "0  2028340880508088487      wittoast42   \n",
              "1  2028339718048317829       CarterVr3   \n",
              "2  2028338322825691536       ekascloud   \n",
              "3  2028338266810834966  Timothy_Hughes   \n",
              "4  2028337959343206567   flarestartcom   \n",
              "\n",
              "                                                text  \n",
              "0  Gratitude is a visibility strategy.\\n\\nRead mo...  \n",
              "1  You don’t need to be a programmer to use AI.\\n...  \n",
              "2  Why Choose Eka Cloud Full Course Explanation &...  \n",
              "3  The AI Easy-Button: Why thinking still matters...  \n",
              "4  Building Sacred: A Privacy-First Period Tracke...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c61093a5-4b97-48cd-9a8d-76fbbb9dd849\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>username</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2028340880508088487</td>\n",
              "      <td>wittoast42</td>\n",
              "      <td>Gratitude is a visibility strategy.\\n\\nRead mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2028339718048317829</td>\n",
              "      <td>CarterVr3</td>\n",
              "      <td>You don’t need to be a programmer to use AI.\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2028338322825691536</td>\n",
              "      <td>ekascloud</td>\n",
              "      <td>Why Choose Eka Cloud Full Course Explanation &amp;...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2028338266810834966</td>\n",
              "      <td>Timothy_Hughes</td>\n",
              "      <td>The AI Easy-Button: Why thinking still matters...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2028337959343206567</td>\n",
              "      <td>flarestartcom</td>\n",
              "      <td>Building Sacred: A Privacy-First Period Tracke...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c61093a5-4b97-48cd-9a8d-76fbbb9dd849')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c61093a5-4b97-48cd-9a8d-76fbbb9dd849 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c61093a5-4b97-48cd-9a8d-76fbbb9dd849');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"tweet_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39736053061887,\n        \"min\": 2028206170872090861,\n        \"max\": 2028340880508088487,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          2028247944936239282,\n          2028221368043454832,\n          2028277676969279741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 200,\n        \"samples\": [\n          \"PRHahnJR\",\n          \"AnalyticsVidhya\",\n          \"NeronWakeUp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"Tiny but Mighty: A Pocket-Sized Quadruped #Robot\\nvia @ZappyZappy7\\n\\n#Robotics #Engineering #ArtificialIntelligence #Innovation #Technology https://t.co/I1feUu69ih\",\n          \"@CoinCrazeCen Key themes:\\n\\u2022 Specialized, efficient models\\n\\u2022 Lower inference costs\\n\\u2022 AI agents standardizing communication\\n2026 will be defined by integration, not announcement cycles.\\n#ArtificialIntelligence #CloudComputing #FutureTech\",\n          \"\\ud83d\\ude80 Wrapped up my Samsung Innovation Campus (SIC) journey \\u2014 truly transformational. \\ud83d\\udc99\\n\\nGrateful to @Samsung for the opportunity \\ud83d\\ude4f\\nSpecial thanks to B. Padmaja Ma\\u2019am \\ud83c\\udf38\\nSIC ends. My AI journey begins. \\ud83e\\udd16\\u2728\\n\\n#AI #MachineLearning #SIC_india_2025 https://t.co/UwZmkHZ4wr\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"tweets_raw.csv\", index=False)\n",
        "print(\"File saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6eALh2p36GX",
        "outputId": "2c6d7aa1-a404-4de6-f677-ee90d9148954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"tweets_raw.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PjqZM4XD4B7Y",
        "outputId": "29152b51-577d-41e0-cbca-bfeffa8c8f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8b4b628a-77d9-4c81-a276-36ec4b5d7a08\", \"tweets_raw.csv\", 77477)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from google.colab import files\n",
        "\n",
        "df = pd.read_csv(\"tweets_raw.csv\")\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "df = df.dropna(subset=[\"tweet_id\", \"username\", \"text\"])\n",
        "\n",
        "df[\"tweet_id\"] = df[\"tweet_id\"].astype(str)\n",
        "\n",
        "df[\"clean_text\"] = df[\"text\"].str.replace(r\"http\\S+|www\\.\\S+\", \"\", regex=True)\n",
        "df[\"clean_text\"] = df[\"clean_text\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
        "df[\"clean_text\"] = df[\"clean_text\"].str.strip().str.lower()\n",
        "\n",
        "print(\"Total rows after cleaning:\", len(df))\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "print(\"\\nDuplicate tweet_id count:\", df[\"tweet_id\"].duplicated().sum())\n",
        "print(\"Empty clean_text rows:\", (df[\"clean_text\"].str.len() == 0).sum())\n",
        "\n",
        "df.to_csv(\"tweets_cleaned.csv\", index=False)\n",
        "\n",
        "files.download(\"tweets_cleaned.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "sR9m5Myz4wnl",
        "outputId": "270329f7-7148-4958-e4fa-1dac4114af14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total rows after cleaning: 300\n",
            "\n",
            "Missing values:\n",
            " tweet_id      0\n",
            "username      0\n",
            "text          0\n",
            "clean_text    0\n",
            "dtype: int64\n",
            "\n",
            "Duplicate tweet_id count: 0\n",
            "Empty clean_text rows: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8d6e3c06-67e9-42f3-ba39-11851a5ece64\", \"tweets_cleaned.csv\", 135289)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question (5 points)\n",
        "\n",
        "Provide your thoughts on the assignment. What did you find challenging, and what aspects did you enjoy? Your opinion on the provided time to complete the assignment."
      ],
      "metadata": {
        "id": "q8BFCvWp32cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For me , this assignment was an extensive and practical experience in web scraping, text preprocessing, and natural language processing. The ability to deal with API limitations and compatibility was one of the most difficult points, especially when dealing with various libraries in Google Colab. The patience and debugging abilities were necessary to manage pagination, rate limits, and periodic package dependency errors. Moreover, syntax analysis like constituency and dependency parsing was also technically challenging since it involved both linguistic theory and details of how the tool works.\n",
        "Nevertheless, I found the practicality of the assignment very enjoyable. The practical aspect of learning was achieved through the collection of real-world data on sources such as Semantic Scholar, GitHub Marketplace, and twitter. This preprocessing and data quality process was especially rewarding since it was used to convert unstructured, sloppy data into organized and interpretable data. Another thing that I liked about the assignment was that it combined several NLP tasks: POS tagging, parsing, and named entity recognition, which helped me understand the interaction between various methods in text analytics.\n",
        "\n",
        "As far as the time available to get through with the assignment is concerned, it was decent but demanded regular effort and time management. Due to the fact that the tasks were to be carried out in the API set up, debugging, and processing of large data, the students had to dedicate enough time to testing and troubleshooting. Generally, the assignment itself was well-designed to train the practical skills in both NLP and data engineering, and it was a helpful experience.\n"
      ],
      "metadata": {
        "id": "JbTa-jDS-KFI"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a11b5c153ab249319cc92c6fce2ed9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b1a0c48596345d9bec6c6ff07b3e84f",
              "IPY_MODEL_084b2177d285443084b3a06330d0b50d",
              "IPY_MODEL_6d2e92bced7f4e7882f77ceff1b94b1b"
            ],
            "layout": "IPY_MODEL_fdfba996045f4a4694698d9d21f64cf0"
          }
        },
        "8b1a0c48596345d9bec6c6ff07b3e84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6022d14e407a47a3915c7645d45d928f",
            "placeholder": "​",
            "style": "IPY_MODEL_d97c6aa161be4669a1f48f738535ac14",
            "value": "Collected abstracts:  18%"
          }
        },
        "084b2177d285443084b3a06330d0b50d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c5c5bdec034ad98416bfc9b660f8a5",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12b497a3d2b4471088fe51c59d086df9",
            "value": 1836
          }
        },
        "6d2e92bced7f4e7882f77ceff1b94b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5861860a8e704f7186ad70eb9749f3f9",
            "placeholder": "​",
            "style": "IPY_MODEL_360aca54cf064bf19fcd40c57408e8bc",
            "value": " 1836/10000 [00:03&lt;00:29, 278.30paper/s]"
          }
        },
        "fdfba996045f4a4694698d9d21f64cf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6022d14e407a47a3915c7645d45d928f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d97c6aa161be4669a1f48f738535ac14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73c5c5bdec034ad98416bfc9b660f8a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b497a3d2b4471088fe51c59d086df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5861860a8e704f7186ad70eb9749f3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "360aca54cf064bf19fcd40c57408e8bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88f7ece4871b493fb5b2da136ec8e970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47392a21d18c4d77884c2ec8f9313bc9",
              "IPY_MODEL_9407c5d9cdf14caa9c2179d8f1aa6cf0",
              "IPY_MODEL_52a24b312bb849888fd9d89bf5f803a3"
            ],
            "layout": "IPY_MODEL_a87b1969962346218847fc0a5b8733e4"
          }
        },
        "47392a21d18c4d77884c2ec8f9313bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdbcf034a6c940fa8de3ed2e69395b16",
            "placeholder": "​",
            "style": "IPY_MODEL_c7b74f3a2c3c41e9b0283b59a087a931",
            "value": "Scraping actions: 100%"
          }
        },
        "9407c5d9cdf14caa9c2179d8f1aa6cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac2c914905aa40beb0bd2f67fb6b39d7",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d9faf36779b4878a455e4118bb2b320",
            "value": 1000
          }
        },
        "52a24b312bb849888fd9d89bf5f803a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16cb7d5c4c4e41d996dcaeb80e40cc32",
            "placeholder": "​",
            "style": "IPY_MODEL_84b566da6ec3493185537a9165d0ba9d",
            "value": " 1000/1000 [01:40&lt;00:00,  9.90action/s]"
          }
        },
        "a87b1969962346218847fc0a5b8733e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdbcf034a6c940fa8de3ed2e69395b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b74f3a2c3c41e9b0283b59a087a931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac2c914905aa40beb0bd2f67fb6b39d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9faf36779b4878a455e4118bb2b320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16cb7d5c4c4e41d996dcaeb80e40cc32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84b566da6ec3493185537a9165d0ba9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}